# Configuration for YAMK Thesis Project
project:
  name: "YAMK Thesis - LLM Evaluation"
  version: "0.2.0"
  description: "Multi-agent system for LLM evaluation"

compute:
  device: "auto"  # auto-detect GPU/CPU
  mixed_precision: true
  compile_model: false  # Set to true for PyTorch 2.0 compilation

models:
  cache_dir: "./models/checkpoints"
  available:
    - name: "mistral"
      model_id: "mistralai/Mistral-7B-Instruct-v0.2"
      #quantization: "4bit"
      quantization: "8bit"
    - name: "gemma_7b_it_4bit"
      model_id: "google/gemma-7b-it"
      #quantization: "4bit"
      quantization: "8bit"
    - name: "Falcon3-7B-Base"
      model_id: "tiiuae/Falcon3-7B-Base"
      #quantization: "4bit"
      quantization: "8bit"
    - name: "Meta-Llama-3-8B-Instruct"
      model_id: "meta-llama/Meta-Llama-3-8B-Instruct"
      #quantization: "4bit"
      quantization: "8bit"
    - name: "Qwen2-7B-Instruct"
      model_id: "Qwen/Qwen2-7B-Instruct"
      #quantization: "4bit"
      quantization: "8bit"
    # LISÄÄ TÄMÄ: Pienempi fallback malli evaluaattoriksi
    - name: "gemma_2b_it"
      model_id: "google/gemma-2b-it"
      quantization: "4bit"

agents:
  uc_agent:
    name: "UC Agent"
    description: "Generates use cases from requirements and user stories"
    system_prompt: |
      You are a specialized AI agent for generating use cases from requirements and user stories.
      Follow these rules:
      1. Generate clear, structured use cases
      2. Include actors, preconditions, main flow, and postconditions
      3. Focus on testability and clarity
      4. Use standard use case format
    
  rf_agent:
    name: "RF Agent"
    description: "Converts use cases to Robot Framework test cases"
    system_prompt: |
      You are a specialized AI agent for converting use cases to Robot Framework test cases.
      Follow these rules:
      1. Use Browser library keywords
      2. Target the-internet.herokuapp.com for testing
      3. Create executable test cases
      4. Include proper test setup and teardown
      5. Use descriptive test and keyword names
      6. Use appropriate selectors (id, css, xpath, text)
      7. Include waits for dynamic elements
      8. Add verification steps

evaluation:
  batch_size: 8
  sample_size: 3  # Evaluoi vain 3 tiedostoa per malli
  full_evaluation: false  # true = kaikki tiedostot
  # Maksimi mallien määrä kerralla (suositus)
  max_models_per_run: 3
  metrics:
    - bleu
    - rouge
    - bertscore
    - semantic_similarity
  llm_evaluation:
    enabled: true
    max_files_per_model: 5  # Rajoita tiedostomäärää muistin säästämiseksi
    # Prioriteettijärjestys evaluaattorimalleille
    evaluator_models:
      - "mistral"
      - "gemma_7b_it_4bit"
      - "Falcon3-7B-Base"
      - "Meta-Llama-3-8B-Instruct"
      - "Qwen2-7B-Instruct"
      - "gemma_2b_it"  # Fallback
    criteria:
      use_case:
        - completeness
        - clarity
        - testability
        - technical_accuracy
        - structure
      test_case:
        - syntax_correctness
        - test_coverage
        - best_practices
        - maintainability
        - executability

extended_metrics:
  enabled: true
  
  quality:
    - bleu
    - rouge
    - bertscore
    - perplexity
    - diversity
    - coherence
    
  performance:
    - inference_time
    - tokens_per_second
    - memory_usage
    - gpu_utilization
    - energy_consumption
    - thermal_metrics
    
  rf_specific:
    - keyword_reuse
    - documentation_coverage
    - error_handling
    - data_driven_usage
    - explicit_waits
    - selector_quality

monitoring:
  wandb:
    enabled: true
    project: "yamk-thesis-evaluation"

paths:
  base_url: "https://the-internet.herokuapp.com"
  requirements_dir: "data/requirements"
  user_stories_dir: "data/user_stories"
  test_cases_dir: "data/test_cases"
  results_dir: "results"

logging:
  level: "INFO"
  file: "logs/yamk_thesis.log"
