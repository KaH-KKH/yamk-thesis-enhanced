,completeness,test_validity,generation_time,memory_usage,llm_uc_score,llm_tc_score,perplexity,coherence,readability,num_runs,composite_score,rank
Qwen2-7B-Instruct,1,1,0.8698565622920775,0.8132499109016751,1.0,0.0,0.0,0.9547276027379603,0.0,1,0.6264260084368569,4.0
gemma_7b_it_4bit,1,1,0.7350416537519078,0.9148418009741417,1.0,1.0,0.04193071808597737,0.6398783977451642,1.0,1,0.8146325078396879,1.0
mistral,1,1,0.716197730689291,0.0,1.0,0.8571428571428553,0.11256245365868134,1.0,0.2747179111341705,1,0.6622912169583333,3.0
Meta-Llama-3-8B-Instruct,1,1,1.0,1.0,1.0,0.5714285714285711,0.022396361099124906,0.0,0.9820041376659523,1,0.7306476744659609,2.0
Falcon3-7B-Base,1,1,0.0,0.8672170963185892,0.0,0.14285714285714213,1.0,0.4055367408571546,0.9725472257477273,1,0.5986842450867349,5.0
