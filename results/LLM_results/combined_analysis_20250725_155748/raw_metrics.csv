,completeness,test_validity,generation_time,memory_usage,llm_uc_score,llm_tc_score,perplexity,coherence,readability,num_runs,composite_score,rank
Qwen2-7B-Instruct,1.0,1.0,1023.9494504928589,-65.19921875,10.0,7.6,23.311321258544922,0.1837809681892395,39.92725521052401,1,0.6264260084368569,4.0
gemma_7b_it_4bit,1.0,1.0,1295.886352777481,-185.45703125,10.0,8.3,22.723668098449707,0.17395344376564026,61.75384814426563,1,0.8146325078396879,1.0
mistral,1.0,1.0,1333.8966746330261,897.47265625,10.0,8.2,21.733774185180664,0.18519407510757446,45.923411228457354,1,0.6622912169583333,3.0
Meta-Llama-3-8B-Instruct,1.0,1.0,761.4354326725006,-286.26171875,10.0,8.0,22.99743938446045,0.15398064255714417,61.36105978260872,1,0.7306476744659609,2.0
Falcon3-7B-Base,1.0,1.0,2778.5484154224396,-129.08203125,9.7,7.699999999999999,9.2964608669281,0.1666388362646103,61.15464761575937,1,0.5986842450867349,5.0
