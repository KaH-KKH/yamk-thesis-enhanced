,completeness,test_validity,generation_time,memory_usage,llm_uc_score,llm_tc_score,perplexity,coherence,readability,composite_score,rank
mistral,1.0,1.0,1.0,0.7296273692331268,1.0,0.8148148148148148,0.0,1.0,0.44448714091226954,0.7765477027733568,2.0
Meta-Llama-3-8B-Instruct,1.0,1.0,0.911271849888559,0.0,1.0,1.0,1.0,0.7090160786578931,0.9199892440171118,0.8378085747292848,1.0
Qwen2-7B-Instruct,1.0,1.0,0.9077360107316408,0.5251758265565472,0.7499999999999956,0.0,0.09440356388342697,0.13537493298202188,0.0,0.49029892601707026,5.0
Falcon3-7B-Base,1.0,1.0,0.0,1.0,0.0,0.6296296296296295,0.8791390482914121,0.6030416262568424,0.8130886342804123,0.6583221042731441,4.0
gemma_7b_it_4bit,1.0,1.0,0.9319468790295444,0.8294733393571432,1.0,0.4814814814814819,0.6799413446996951,0.0,1.0,0.7692047827297627,3.0
