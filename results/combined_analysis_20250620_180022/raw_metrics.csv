,completeness,test_validity,generation_time,memory_usage,llm_uc_score,llm_tc_score,perplexity,coherence,readability,num_runs,composite_score,rank
mistral,1.0,1.0,1248.0343911647797,520.517578125,10.0,7.949999999999999,21.80858278274536,0.2531350553035736,47.530183846148645,2,0.7765477027733568,2.0
Meta-Llama-3-8B-Instruct,1.0,1.0,1407.9804105758667,1599.27734375,10.0,8.2,12.195959091186523,0.21864238381385803,64.06826979812988,1,0.8378085747292848,1.0
Qwen2-7B-Instruct,1.0,1.0,1414.3542997837067,822.80078125,9.95,6.85,20.901116847991943,0.15064407140016556,32.07080628933328,2,0.49029892601707026,5.0
Falcon3-7B-Base,1.0,1.0,3050.6868662834167,120.76953125,9.8,7.699999999999999,13.357749938964844,0.2060803771018982,60.35023898270164,1,0.6583221042731441,4.0
gemma_7b_it_4bit,1.0,1.0,1370.7105181217194,372.89453125,10.0,7.5,15.272562503814697,0.13459698855876923,66.85106455526736,1,0.7692047827297627,3.0
