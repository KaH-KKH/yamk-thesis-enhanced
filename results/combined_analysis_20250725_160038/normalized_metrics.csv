,completeness,test_validity,generation_time,memory_usage,llm_uc_score,llm_tc_score,perplexity,coherence,readability,num_runs,composite_score,rank
stablelm_3b,1,1,0.9935264478002114,0.9666283376253264,1.0,0.9285714285714284,0.692331996147621,0.07287790391183167,0.8183049247526285,1,0.8302490043121163,1.0
phi2,1,1,0.8668053413308772,0.0,1.0,0.8571428571428569,0.9375322275396057,0.026377058598514802,0.9146434505007476,1,0.7336112150125114,6.0
opt_1.3b,1,1,1.0,0.9642559223448153,0.0,0.8809523809523808,0.0,1.0,0.0,1,0.649467589255244,9.0
tinyllama,1,1,0.9914371900267869,0.8291950862247145,0.7343750000000001,0.6904761904761904,1.0,0.15412520754147774,0.8822955568783678,1,0.8091004701275042,3.0
pythia_1b,1,1,0.9969043759049276,0.9690347450220109,0.0,0.0,0.0,1.0,0.0,1,0.5517710134363265,10.0
Qwen2-7B-Instruct,1,1,0.6466348372353103,0.9778887145002163,1.0,0.8333333333333331,0.706911236067242,0.0352241652273402,0.06838813417791276,1,0.6964867133934839,8.0
gemma_7b_it_4bit,1,1,0.546415996313933,0.9899172350578276,1.0,1.0,0.7171638424502531,0.02360797188951454,1.0,1,0.8085672273012809,4.0
mistral,1,1,0.5324077820281639,0.8815995986586007,1.0,0.9761904761904758,0.7344342212091144,0.03689446615592197,0.3243185999443637,1,0.7206494604651822,7.0
Meta-Llama-3-8B-Instruct,1,1,0.7433809955188744,1.0,1.0,0.9285714285714284,0.7123874378887868,0.0,0.9832348411139005,1,0.8186194114547768,2.0
Falcon3-7B-Base,1,1,0.0,0.9842784509128446,0.9531249999999999,0.8571428571428569,0.9514242530393949,0.014962061560537188,0.9744246697568477,1,0.7483730324902756,5.0
