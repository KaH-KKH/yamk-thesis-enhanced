{
  "timestamp": "2025-06-07T14:18:10.214344",
  "models": [
    "gemma_7b_it_4bit"
  ],
  "summary": {
    "best_scores": {
      "quality_perplexity": {
        "model": "gemma_7b_it_4bit",
        "value": 17.654382705688477
      }
    }
  },
  "detailed_metrics": {
    "standard": {
      "use_case_metrics": {
        "gemma_7b_it_4bit": {
          "custom": {
            "completeness": 1.0,
            "avg_length": 170.0,
            "avg_steps": 16.0
          }
        }
      },
      "test_case_metrics": {
        "gemma_7b_it_4bit": {
          "syntax_validity": {
            "valid_count": 1,
            "total_count": 1,
            "validity_rate": 1.0
          },
          "keyword_coverage": {
            "keyword_counts": {
              "New Browser": 1,
              "New Page": 0,
              "Go To": 1,
              "Click": 2,
              "Type Text": 3,
              "Get Text": 0,
              "Wait For Elements State": 1,
              "Take Screenshot": 1
            },
            "total_keywords": 9,
            "unique_keywords_used": 6,
            "coverage_rate": 0.75
          }
        }
      }
    },
    "extended": {
      "quality": {
        "gemma_7b_it_4bit": {
          "perplexity": {
            "mean_perplexity": 17.654382705688477,
            "min_perplexity": 17.654382705688477,
            "max_perplexity": 17.654382705688477,
            "std_perplexity": 0.0
          },
          "diversity": {
            "self_bleu": 0.0,
            "distinct_1": 0.504950495049505,
            "distinct_2": 0.8258706467661692,
            "distinct_3": 0.94,
            "vocabulary_size": 102,
            "token_type_ratio": 0.504950495049505
          },
          "coherence": {
            "mean_coherence": 0.20102892816066742,
            "min_coherence": 0.20102892816066742,
            "max_coherence": 0.20102892816066742,
            "std_coherence": 0.0
          }
        }
      },
      "user_experience": {
        "gemma_7b_it_4bit": {
          "readability": {
            "flesch_reading_ease": {
              "score": 54.90961788617889,
              "interpretation": "Fairly Difficult"
            },
            "flesch_kincaid_grade": {
              "score": 8.31668292682927,
              "interpretation": "Grade level: 8.3"
            },
            "gunning_fog": {
              "score": 9.251382113821139,
              "interpretation": "Years of education needed: 9.3"
            },
            "smog_index": {
              "score": 9.725611199111238,
              "interpretation": "Score: 9.73"
            },
            "automated_readability_index": {
              "score": 7.281901960784317,
              "interpretation": "Score: 7.28"
            },
            "coleman_liau_index": {
              "score": 9.148780487804881,
              "interpretation": "Score: 9.15"
            },
            "linsear_write_formula": {
              "score": 4.909090909090909,
              "interpretation": "Score: 4.91"
            },
            "dale_chall_readability_score": {
              "score": 13.036598211382113,
              "interpretation": "Score: 13.04"
            },
            "avg_sentence_length": 11.263157894736842,
            "avg_word_length": 3.939252336448598,
            "syllables_per_word": 1.2757009345794392,
            "overall_readability": "Moderate - Requires some effort"
          },
          "clarity": {
            "specificity_score": 0.0049504950495049506,
            "vagueness_score": 0.0,
            "structure_score": 0.0,
            "conditional_clarity": 0.019801980198019802,
            "ambiguity_score": 0.2675077399380805,
            "overall_clarity": 0.0019801980198019802
          },
          "actionability": {
            "action_verb_density": 0.024752475247524754,
            "step_clarity": 0.6153846153846154,
            "executable_steps": 0.6153846153846154,
            "overall_actionability": 0.41850723533891854
          },
          "completeness": {
            "completeness_score": 1.0,
            "missing_elements": []
          },
          "usability": {
            "navigation_ease": 1.0,
            "information_findability": 0.8255451713395638,
            "consistency_score": 1.0,
            "user_friendliness": 0.7456476964769646
          },
          "accessibility": {
            "plain_language_score": 0.8762376237623762,
            "technical_jargon_ratio": 0.0,
            "international_friendly": 1.0
          }
        }
      },
      "robot_framework": {
        "gemma_7b_it_4bit": {
          "overall_quality": {
            "total_tests": 3,
            "documentation_coverage": 0.0,
            "tag_coverage": 0.0,
            "verification_coverage": 0.3333333333333333
          },
          "keyword_analysis": {
            "total_keywords_used": 25,
            "unique_keywords": 10,
            "custom_keywords_defined": 3,
            "keyword_reuse_ratio": 0.3,
            "browser_keyword_usage": {
              "interaction": 2
            },
            "most_used_keywords": {
              "...": 10,
              "Type": 3,
              "Log": 3,
              "Click": 2,
              "New": 2,
              "Set": 1,
              "Take": 1,
              "Close": 1,
              "Go": 1,
              "Wait": 1
            }
          },
          "structure_analysis": {
            "avg_test_length": 3.6666666666666665,
            "max_test_length": 6,
            "min_test_length": 2,
            "avg_complexity": 1.0,
            "max_complexity": 1
          },
          "best_practices": {
            "selector_usage": {
              "id": 2,
              "css": 2,
              "xpath": 0,
              "text": 1,
              "data_test": 0,
              "aria": 0
            },
            "best_selector_ratio": 0.4,
            "explicit_wait_usage": 1,
            "implicit_wait_usage": 0,
            "wait_strategy_score": 1.0,
            "error_handling_present": false,
            "screenshot_usage": 1,
            "data_driven_testing": false,
            "template_usage": 0,
            "loop_usage": 0
          },
          "individual_files": {
            "example_login_use_case.robot": {
              "syntax_valid": true,
              "sections": [
                "Settings",
                "Variables",
                "Keywords"
              ],
              "test_count": 1,
              "keyword_count": 3,
              "documentation_present": true,
              "tags_present": true,
              "setup_teardown": {
                "test_setup": true,
                "test_teardown": true,
                "suite_setup": false,
                "suite_teardown": false
              },
              "line_count": 57,
              "non_empty_lines": 49
            }
          }
        }
      },
      "test_case_ux": {
        "gemma_7b_it_4bit": {
          "readability": {
            "flesch_reading_ease": {
              "score": 30.069384076763498,
              "interpretation": "Difficult"
            },
            "flesch_kincaid_grade": {
              "score": 12.807196576763488,
              "interpretation": "Grade level: 12.8"
            },
            "gunning_fog": {
              "score": 12.829979253112032,
              "interpretation": "Years of education needed: 12.8"
            },
            "smog_index": {
              "score": 12.602617957971052,
              "interpretation": "Score: 12.60"
            },
            "automated_readability_index": {
              "score": 15.463212264150947,
              "interpretation": "Score: 15.46"
            },
            "coleman_liau_index": {
              "score": 17.443983402489625,
              "interpretation": "Score: 17.44"
            },
            "linsear_write_formula": {
              "score": 7.444444444444445,
              "interpretation": "Score: 7.44"
            },
            "dale_chall_readability_score": {
              "score": 13.228620746887968,
              "interpretation": "Score: 13.23"
            },
            "avg_sentence_length": 47.375,
            "avg_word_length": 4.37730870712401,
            "syllables_per_word": 1.2137203166226913,
            "overall_readability": "Poor - Difficult to understand"
          },
          "clarity": {
            "specificity_score": 0.0,
            "vagueness_score": 0.0,
            "structure_score": 0.0,
            "conditional_clarity": 0.010554089709762533,
            "ambiguity_score": 0.44666666666666666,
            "overall_clarity": 0.0
          },
          "actionability": {
            "action_verb_density": 0.03430079155672823,
            "instruction_quality": 0.75,
            "overall_actionability": 0.39215039577836414
          },
          "completeness": {
            "completeness_score": 0.8,
            "missing_elements": [
              "error handling"
            ]
          },
          "usability": {
            "navigation_ease": 0.3333333333333333,
            "information_findability": 0.4547053649956025,
            "consistency_score": 1.0,
            "user_friendliness": 0.3333333333333333
          },
          "accessibility": {
            "plain_language_score": 0.8496042216358839,
            "technical_jargon_ratio": 0.0079155672823219,
            "international_friendly": 1.0
          }
        }
      },
      "system_info": {
        "gemma_7b_it_4bit": {
          "cpu": {
            "physical_cores": 12,
            "logical_cores": 24,
            "max_frequency": 0.0,
            "cpu_model": "x86_64"
          },
          "memory": {
            "total_gb": 15.460460662841797,
            "available_gb": 9.334110260009766
          },
          "gpu": [
            {
              "name": "NVIDIA RTX 2000 Ada Generation Laptop GPU",
              "memory_total_mb": 8188.0,
              "driver_version": "538.92",
              "compute_capability": [
                8,
                9
              ],
              "pcie_link_width": 8,
              "pcie_link_gen": 4
            }
          ]
        }
      }
    }
  },
  "performance_comparison": {
    "gemma_7b_it_4bit": {
      "use_case_generation_detailed": {
        "total_time": 244.6394829750061,
        "cpu": {
          "mean_percent": 4.011176470588236,
          "max_percent": 7.1,
          "min_percent": 0.0,
          "std_percent": 0.8113850348265517
        },
        "memory": {
          "mean_mb": 5944.901114430147,
          "max_mb": 6074.1640625,
          "min_mb": 5827.71875,
          "peak_mb": 246.4453125
        },
        "gpu": {
          "mean_percent": 80.51176470588236,
          "max_percent": 100,
          "mean_memory_mb": 7688.417647058824,
          "max_memory_mb": 7793.0,
          "peak_memory_mb": 5220.0,
          "mean_temperature": 56.01470588235294,
          "max_temperature": 58.0,
          "mean_power_watts": 27.41949705882353,
          "max_power_watts": 31.04,
          "total_energy_joules": 6707.891583905289
        },
        "efficiency": {
          "cpu_efficiency": 95.98882352941176,
          "memory_efficiency": 62.44893589416782,
          "gpu_efficiency": 19.488235294117644,
          "performance_per_watt": 36.470399068760535
        }
      },
      "test_case_generation_detailed": {
        "total_time": 566.6138744354248,
        "cpu": {
          "mean_percent": 4.227735368956743,
          "max_percent": 8.5,
          "min_percent": 0.0,
          "std_percent": 0.7563601140213372
        },
        "memory": {
          "mean_mb": 5943.546368082061,
          "max_mb": 6084.7265625,
          "min_mb": 5848.27734375,
          "peak_mb": 236.44921875
        },
        "gpu": {
          "mean_percent": 86.80916030534351,
          "max_percent": 100,
          "mean_memory_mb": 7751.274809160305,
          "max_memory_mb": 7799.0,
          "peak_memory_mb": 5200.0,
          "mean_temperature": 57.525445292620866,
          "max_temperature": 59.0,
          "mean_power_watts": 28.8485737913486,
          "max_power_watts": 31.253,
          "total_energy_joules": 16346.002167852283
        },
        "efficiency": {
          "cpu_efficiency": 95.77226463104326,
          "memory_efficiency": 62.45749317140169,
          "gpu_efficiency": 13.19083969465649,
          "performance_per_watt": 34.663758674263825
        }
      },
      "use_case_generation": {
        "total_time": 243.77384233474731,
        "memory_used": 120.9609375,
        "avg_time_per_file": 243.77384233474731
      },
      "test_case_generation": {
        "total_time": 565.7960364818573,
        "memory_used": 95.30859375
      },
      "total_time": 809.5698788166046,
      "total_memory": 216.26953125,
      "files_per_second": 0.0041021628507082065
    }
  },
  "recommendations": [
    "Overall recommendation: **gemma_7b_it_4bit** (best in 1 metrics)",
    "\n**Extended Metrics Insights:**"
  ],
  "extended_analysis": {
    "consistency": {},
    "trade_offs": {
      "gemma_7b_it_4bit": {
        "quality_score": 0,
        "speed_quality_ratio": 0.0,
        "memory_quality_ratio": 0.0,
        "efficiency_score": 0.0
      }
    },
    "scalability": {
      "gemma_7b_it_4bit": {
        "files_per_second": 0.0041021628507082065,
        "memory_efficiency": 9.247719678497246,
        "time_complexity": "O(nÂ²) - Quadratic"
      }
    },
    "robustness": {
      "gemma_7b_it_4bit": {
        "error_rate": 0.0,
        "success_rate": 1.0,
        "graceful_failure": false,
        "reliability_score": 100.0
      }
    },
    "statistical_significance": {},
    "ranking": [
      {
        "model": "gemma_7b_it_4bit",
        "composite_score": 0.0014647709153467656,
        "scores": {
          "completeness": 0.0,
          "validity": 0.0,
          "speed": 0.00123522382213844,
          "memory": 0.004623859839248623
        },
        "rank": 1
      }
    ],
    "recommendations": [
      "Recommended model: gemma_7b_it_4bit (highest composite score)",
      "gemma_7b_it_4bit needs improvement in: completeness, validity, speed, memory",
      "Best quality/performance balance: gemma_7b_it_4bit"
    ]
  }
}