{
  "model": "mistral",
  "timestamp": "2025-06-07T18:17:16.457843",
  "use_case_generation": {
    "generation_report": {
      "total_files": 1,
      "successful": 1,
      "failed": 0,
      "results": [
        {
          "requirement": "example_login.txt",
          "use_case": "example_login_use_case.json",
          "status": "success"
        }
      ]
    },
    "performance": {
      "total_time": 311.99839997291565,
      "memory_used": -625.16796875,
      "avg_time_per_file": 311.99839997291565
    }
  },
  "test_case_generation": {
    "generation_report": {
      "model": "mistral",
      "timestamp": "2025-06-07T18:42:11.609499",
      "total_files": 2,
      "successful": 2,
      "failed": 0,
      "results": [
        {
          "use_case": "example_login_use_case.txt",
          "test_case": "example_login_use_case.robot",
          "status": "success"
        },
        {
          "use_case": "example_login_use_case.json",
          "test_case": "example_login_use_case.robot",
          "status": "success"
        }
      ]
    },
    "test_validation": {
      "executable": 0,
      "failed": 1,
      "errors": [
        {
          "file": "example_login_use_case.robot",
          "error": ""
        }
      ],
      "executability_rate": 0.0
    },
    "performance": {
      "total_time": 1179.3444106578827,
      "memory_used": 183.4921875
    }
  },
  "metrics": {
    "standard": {
      "use_case_metrics": {
        "custom": {
          "completeness": 1.0,
          "avg_length": 217.0,
          "avg_steps": 26.0
        }
      },
      "test_case_metrics": {
        "syntax_validity": {
          "valid_count": 1,
          "total_count": 1,
          "validity_rate": 1.0
        },
        "keyword_coverage": {
          "keyword_counts": {
            "New Browser": 2,
            "New Page": 1,
            "Go To": 1,
            "Click": 6,
            "Type Text": 4,
            "Get Text": 0,
            "Wait For Elements State": 2,
            "Take Screenshot": 2
          },
          "total_keywords": 18,
          "unique_keywords_used": 7,
          "coverage_rate": 0.875
        }
      }
    },
    "extended": {
      "quality": {
        "perplexity": {
          "mean_perplexity": 18.880348205566406,
          "min_perplexity": 18.880348205566406,
          "max_perplexity": 18.880348205566406,
          "std_perplexity": 0.0
        },
        "diversity": {
          "self_bleu": 0.0,
          "distinct_1": 0.4223826714801444,
          "distinct_2": 0.7391304347826086,
          "distinct_3": 0.8836363636363637,
          "vocabulary_size": 117,
          "token_type_ratio": 0.4223826714801444
        },
        "coherence": {
          "mean_coherence": 0.2301221489906311,
          "min_coherence": 0.2301221489906311,
          "max_coherence": 0.2301221489906311,
          "std_coherence": 0.0
        }
      },
      "user_experience": {
        "readability": {
          "flesch_reading_ease": {
            "score": 54.489000000000004,
            "interpretation": "Fairly Difficult"
          },
          "flesch_kincaid_grade": {
            "score": 7.746000000000002,
            "interpretation": "Grade level: 7.7"
          },
          "gunning_fog": {
            "score": 8.693333333333333,
            "interpretation": "Years of education needed: 8.7"
          },
          "smog_index": {
            "score": 9.174902378510234,
            "interpretation": "Score: 9.17"
          },
          "automated_readability_index": {
            "score": 7.188202764976957,
            "interpretation": "Score: 7.19"
          },
          "coleman_liau_index": {
            "score": 8.985714285714291,
            "interpretation": "Score: 8.99"
          },
          "linsear_write_formula": {
            "score": 4.545454545454546,
            "interpretation": "Score: 4.55"
          },
          "dale_chall_readability_score": {
            "score": 14.279044761904762,
            "interpretation": "Score: 14.28"
          },
          "avg_sentence_length": 6.7272727272727275,
          "avg_word_length": 3.820945945945946,
          "syllables_per_word": 1.2060810810810811,
          "overall_readability": "Moderate - Requires some effort"
        },
        "clarity": {
          "specificity_score": 0.0,
          "vagueness_score": 0.0,
          "structure_score": 0.0,
          "conditional_clarity": 0.0036101083032490976,
          "ambiguity_score": 0.15870629370629372,
          "overall_clarity": 0.0
        },
        "actionability": {
          "action_verb_density": 0.01444043321299639,
          "step_clarity": 0.6190476190476191,
          "executable_steps": 0.6190476190476191,
          "overall_actionability": 0.41751189043607817
        },
        "completeness": {
          "completeness_score": 1.0,
          "missing_elements": []
        },
        "usability": {
          "navigation_ease": 1.0,
          "information_findability": 0.46509009009009006,
          "consistency_score": 1.0,
          "user_friendliness": 0.6248333333333332
        },
        "accessibility": {
          "plain_language_score": 0.8700361010830325,
          "technical_jargon_ratio": 0.0036101083032490976,
          "international_friendly": 1.0
        }
      },
      "robot_framework": {
        "overall_quality": {
          "total_tests": 4,
          "documentation_coverage": 0.25,
          "tag_coverage": 0.25,
          "verification_coverage": 0.5
        },
        "keyword_analysis": {
          "total_keywords_used": 60,
          "unique_keywords": 9,
          "custom_keywords_defined": 3,
          "keyword_reuse_ratio": 0.3333333333333333,
          "browser_keyword_usage": {
            "interaction": 2
          },
          "most_used_keywords": {
            "...": 43,
            "New": 4,
            "Type": 4,
            "Click": 2,
            "Wait": 2,
            "Take": 2,
            "Set": 1,
            "Close": 1,
            "Go": 1
          }
        },
        "structure_analysis": {
          "avg_test_length": 16.25,
          "max_test_length": 54,
          "min_test_length": 2,
          "avg_complexity": 1.25,
          "max_complexity": 2.0
        },
        "best_practices": {
          "selector_usage": {
            "id": 4,
            "css": 3,
            "xpath": 0,
            "text": 1,
            "data_test": 0,
            "aria": 0
          },
          "best_selector_ratio": 0.5,
          "explicit_wait_usage": 2,
          "implicit_wait_usage": 0,
          "wait_strategy_score": 1.0,
          "error_handling_present": false,
          "screenshot_usage": 2,
          "data_driven_testing": false,
          "template_usage": 0,
          "loop_usage": 0
        },
        "individual_files": {
          "example_login_use_case.robot": {
            "syntax_valid": true,
            "sections": [
              "Settings",
              "Variables",
              "Keywords"
            ],
            "test_count": 1,
            "keyword_count": 3,
            "documentation_present": true,
            "tags_present": true,
            "setup_teardown": {
              "test_setup": true,
              "test_teardown": true,
              "suite_setup": false,
              "suite_teardown": false
            },
            "line_count": 92,
            "non_empty_lines": 84
          }
        }
      },
      "test_case_ux": {
        "readability": {
          "flesch_reading_ease": {
            "score": 35.11573684210529,
            "interpretation": "Difficult"
          },
          "flesch_kincaid_grade": {
            "score": 10.249438596491228,
            "interpretation": "Grade level: 10.2"
          },
          "gunning_fog": {
            "score": 11.344093567251463,
            "interpretation": "Years of education needed: 11.3"
          },
          "smog_index": {
            "score": 10.454891242816938,
            "interpretation": "Score: 10.45"
          },
          "automated_readability_index": {
            "score": 12.309625935162096,
            "interpretation": "Score: 12.31"
          },
          "coleman_liau_index": {
            "score": 17.66608187134504,
            "interpretation": "Score: 17.67"
          },
          "linsear_write_formula": {
            "score": 8.75,
            "interpretation": "Score: 8.75"
          },
          "dale_chall_readability_score": {
            "score": 13.339717309941522,
            "interpretation": "Score: 13.34"
          },
          "avg_sentence_length": 19.096774193548388,
          "avg_word_length": 4.305743243243243,
          "syllables_per_word": 1.1199324324324325,
          "overall_readability": "Poor - Difficult to understand"
        },
        "clarity": {
          "specificity_score": 0.005067567567567568,
          "vagueness_score": 0.0,
          "structure_score": 0.0,
          "conditional_clarity": 0.005067567567567568,
          "ambiguity_score": 0.2846061120543294,
          "overall_clarity": 0.002027027027027027
        },
        "actionability": {
          "action_verb_density": 0.03209459459459459,
          "instruction_quality": 1.0,
          "overall_actionability": 0.5160472972972973
        },
        "completeness": {
          "completeness_score": 1.0,
          "missing_elements": [
            "error handling"
          ]
        },
        "usability": {
          "navigation_ease": 0.3333333333333333,
          "information_findability": 0.08952702702702703,
          "consistency_score": 1.0,
          "user_friendliness": 0.3819600389863547
        },
        "accessibility": {
          "plain_language_score": 0.8293918918918919,
          "technical_jargon_ratio": 0.006756756756756757,
          "international_friendly": 1.0
        }
      },
      "system_info": {
        "cpu": {
          "physical_cores": 12,
          "logical_cores": 24,
          "max_frequency": 0.0,
          "cpu_model": "13th Gen Intel(R) Core(TM) i7-13700HX"
        },
        "memory": {
          "total_gb": 15.460460662841797,
          "available_gb": 9.769058227539062,
          "used_gb": 5.295688629150391,
          "percent": 36.8
        },
        "gpu": [
          {
            "id": 0,
            "name": "NVIDIA RTX 2000 Ada Generation Laptop GPU",
            "utilization": 36.0,
            "memory_used": 3532.0,
            "memory_total": 8188.0,
            "temperature": 54.0,
            "driver_version": "538.92",
            "compute_capability": "(8, 9)",
            "pcie_link_width": 8,
            "pcie_link_gen": 4
          }
        ]
      }
    }
  },
  "performance": {
    "use_case_generation_detailed": {
      "total_time": 317.2004578113556,
      "cpu": {
        "mean_percent": 4.2248780487804884,
        "max_percent": 22.7,
        "min_percent": 0.0,
        "std_percent": 1.2889268024993004
      },
      "memory": {
        "mean_mb": 5211.59365472561,
        "max_mb": 5646.703125,
        "min_mb": 5158.359375,
        "peak_mb": 488.34375
      },
      "gpu": {
        "mean_percent": 72.15121951219513,
        "max_percent": 100,
        "mean_memory_mb": 7495.065853658537,
        "max_memory_mb": 7655.0,
        "peak_memory_mb": 3836.0,
        "mean_temperature": 55.604878048780485,
        "max_temperature": 58.0,
        "mean_power_watts": 26.18069756097561,
        "max_power_watts": 29.849,
        "total_energy_joules": 8304.529252162103
      },
      "efficiency": {
        "cpu_efficiency": 95.77512195121952,
        "memory_efficiency": 67.08088433176425,
        "gpu_efficiency": 27.848780487804873,
        "performance_per_watt": 38.19607929357004
      }
    },
    "test_case_generation_detailed": {
      "total_time": 1183.0466239452362,
      "cpu": {
        "mean_percent": 4.293855109961191,
        "max_percent": 17.6,
        "min_percent": 0.4,
        "std_percent": 0.8118031387333567
      },
      "memory": {
        "mean_mb": 5355.234150125323,
        "max_mb": 5456.5078125,
        "min_mb": 5186.83203125,
        "peak_mb": 269.67578125
      },
      "gpu": {
        "mean_percent": 82.65653298835706,
        "max_percent": 100,
        "mean_memory_mb": 7492.271668822768,
        "max_memory_mb": 7696.0,
        "peak_memory_mb": 4479.0,
        "mean_temperature": 56.39650711513583,
        "max_temperature": 60.0,
        "mean_power_watts": 27.258621604139716,
        "max_power_watts": 32.384,
        "total_energy_joules": 32248.220262178165
      },
      "efficiency": {
        "cpu_efficiency": 95.70614489003881,
        "memory_efficiency": 66.17357681779139,
        "gpu_efficiency": 17.343467011642943,
        "performance_per_watt": 36.685640767988495
      }
    },
    "use_case_generation": {
      "total_time": 311.99839997291565,
      "memory_used": -625.16796875,
      "avg_time_per_file": 311.99839997291565
    },
    "test_case_generation": {
      "total_time": 1179.3444106578827,
      "memory_used": 183.4921875
    },
    "total_time": 1491.3428106307983,
    "total_memory": -441.67578125,
    "files_per_second": 0.00320514464204563
  }
}