{
  "model": "Falcon3-7B-Base",
  "timestamp": "2025-06-14T20:59:35.288808",
  "use_case_generation": {
    "generation_report": {
      "total_files": 1,
      "successful": 1,
      "failed": 0,
      "results": [
        {
          "requirement": "example_login.txt",
          "use_case": "example_login_use_case.json",
          "status": "success"
        }
      ]
    },
    "performance": {
      "total_time": 397.18748450279236,
      "memory_used": 225.40234375,
      "avg_time_per_file": 397.18748450279236
    }
  },
  "test_case_generation": {
    "generation_report": {
      "model": "Falcon3-7B-Base",
      "timestamp": "2025-06-14T21:16:54.980236",
      "total_files": 2,
      "successful": 2,
      "failed": 0,
      "results": [
        {
          "use_case": "example_login_use_case.txt",
          "test_case": "example_login_use_case.robot",
          "status": "success"
        },
        {
          "use_case": "example_login_use_case.json",
          "test_case": "example_login_use_case.robot",
          "status": "success"
        }
      ]
    },
    "test_validation": {
      "executable": 0,
      "failed": 1,
      "errors": [
        {
          "file": "example_login_use_case.robot",
          "error": ""
        }
      ],
      "executability_rate": 0.0
    },
    "performance": {
      "total_time": 642.331743478775,
      "memory_used": -165.87109375
    }
  },
  "metrics": {
    "standard": {
      "use_case_metrics": {
        "custom": {
          "completeness": 1.0,
          "avg_length": 415.0,
          "avg_steps": 27.0
        }
      },
      "test_case_metrics": {
        "syntax_validity": {
          "valid_count": 1,
          "total_count": 1,
          "validity_rate": 1.0
        },
        "keyword_coverage": {
          "keyword_counts": {
            "New Browser": 1,
            "New Page": 0,
            "Go To": 2,
            "Click": 2,
            "Type Text": 4,
            "Get Text": 1,
            "Wait For Elements State": 1,
            "Take Screenshot": 1
          },
          "total_keywords": 12,
          "unique_keywords_used": 7,
          "coverage_rate": 0.875
        }
      }
    },
    "extended": {
      "quality": {
        "perplexity": {
          "mean_perplexity": 21.165206909179688,
          "min_perplexity": 21.165206909179688,
          "max_perplexity": 21.165206909179688,
          "std_perplexity": 0.0
        },
        "diversity": {
          "self_bleu": 0.0,
          "distinct_1": 0.5070140280561122,
          "distinct_2": 0.8654618473895582,
          "distinct_3": 0.9517102615694165,
          "vocabulary_size": 253,
          "token_type_ratio": 0.5070140280561122
        },
        "coherence": {
          "mean_coherence": 0.19174422323703766,
          "min_coherence": 0.19174422323703766,
          "max_coherence": 0.19174422323703766,
          "std_coherence": 0.0
        }
      },
      "user_experience": {
        "readability": {
          "flesch_reading_ease": {
            "score": 46.48558823529416,
            "interpretation": "Difficult"
          },
          "flesch_kincaid_grade": {
            "score": 9.78588235294118,
            "interpretation": "Grade level: 9.8"
          },
          "gunning_fog": {
            "score": 11.449000571102228,
            "interpretation": "Years of education needed: 11.4"
          },
          "smog_index": {
            "score": 11.384434051031349,
            "interpretation": "Score: 11.38"
          },
          "automated_readability_index": {
            "score": 10.448703047484052,
            "interpretation": "Score: 10.45"
          },
          "coleman_liau_index": {
            "score": 11.953883495145632,
            "interpretation": "Score: 11.95"
          },
          "linsear_write_formula": {
            "score": 8.571428571428571,
            "interpretation": "Score: 8.57"
          },
          "dale_chall_readability_score": {
            "score": 12.362486750428326,
            "interpretation": "Score: 12.36"
          },
          "avg_sentence_length": 9.666666666666666,
          "avg_word_length": 4.365900383141763,
          "syllables_per_word": 1.3812260536398469,
          "overall_readability": "Poor - Difficult to understand"
        },
        "clarity": {
          "specificity_score": 0.006012024048096192,
          "vagueness_score": 0.0,
          "structure_score": 0.006012024048096192,
          "conditional_clarity": 0.004008016032064128,
          "ambiguity_score": 0.2321205286483064,
          "overall_clarity": 0.0048096192384769546
        },
        "actionability": {
          "action_verb_density": 0.01603206412825651,
          "step_clarity": 0.30434782608695654,
          "executable_steps": 0.5652173913043478,
          "overall_actionability": 0.2951990938398536
        },
        "completeness": {
          "completeness_score": 1.0,
          "missing_elements": []
        },
        "usability": {
          "navigation_ease": 1.0,
          "information_findability": 0.8282247765006385,
          "consistency_score": 1.0,
          "user_friendliness": 0.3948366013071894
        },
        "accessibility": {
          "plain_language_score": 0.8316633266533067,
          "technical_jargon_ratio": 0.0,
          "international_friendly": 1.0
        }
      },
      "robot_framework": {
        "overall_quality": {
          "total_tests": 4,
          "documentation_coverage": 0.25,
          "tag_coverage": 0.25,
          "verification_coverage": 0.5
        },
        "keyword_analysis": {
          "total_keywords_used": 16,
          "unique_keywords": 10,
          "custom_keywords_defined": 3,
          "keyword_reuse_ratio": 0.3,
          "browser_keyword_usage": {
            "interaction": 2
          },
          "most_used_keywords": {
            "Type": 4,
            "Go": 2,
            "Click": 2,
            "New": 2,
            "Log": 1,
            "Get": 1,
            "Set": 1,
            "Take": 1,
            "Close": 1,
            "Wait": 1
          }
        },
        "structure_analysis": {
          "avg_test_length": 4.75,
          "max_test_length": 8,
          "min_test_length": 2,
          "avg_complexity": 1.0,
          "max_complexity": 1
        },
        "best_practices": {
          "selector_usage": {
            "id": 2,
            "css": 2,
            "xpath": 0,
            "text": 1,
            "data_test": 0,
            "aria": 0
          },
          "best_selector_ratio": 0.4,
          "explicit_wait_usage": 1,
          "implicit_wait_usage": 0,
          "wait_strategy_score": 1.0,
          "error_handling_present": false,
          "screenshot_usage": 1,
          "data_driven_testing": false,
          "template_usage": 0,
          "loop_usage": 0
        },
        "individual_files": {
          "example_login_use_case.robot": {
            "syntax_valid": true,
            "sections": [
              "Settings",
              "Variables",
              "Keywords"
            ],
            "test_count": 1,
            "keyword_count": 3,
            "documentation_present": true,
            "tags_present": true,
            "setup_teardown": {
              "test_setup": true,
              "test_teardown": true,
              "suite_setup": false,
              "suite_teardown": false
            },
            "line_count": 45,
            "non_empty_lines": 38
          }
        }
      },
      "test_case_ux": {
        "readability": {
          "flesch_reading_ease": {
            "score": 10.062240437158522,
            "interpretation": "Very Difficult"
          },
          "flesch_kincaid_grade": {
            "score": 16.907213114754096,
            "interpretation": "Grade level: 16.9"
          },
          "gunning_fog": {
            "score": 16.002185792349728,
            "interpretation": "Years of education needed: 16.0"
          },
          "smog_index": {
            "score": 15.247664890283005,
            "interpretation": "Score: 15.25"
          },
          "automated_readability_index": {
            "score": 25.221051282051278,
            "interpretation": "Score: 25.22"
          },
          "coleman_liau_index": {
            "score": 24.818032786885244,
            "interpretation": "Score: 24.82"
          },
          "linsear_write_formula": {
            "score": 13.8,
            "interpretation": "Score: 13.80"
          },
          "dale_chall_readability_score": {
            "score": 15.516836612021857,
            "interpretation": "Score: 15.52"
          },
          "avg_sentence_length": 220.0,
          "avg_word_length": 4.6045454545454545,
          "syllables_per_word": 1.1545454545454545,
          "overall_readability": "Poor - Difficult to understand"
        },
        "clarity": {
          "specificity_score": 0.0,
          "vagueness_score": 0.0,
          "structure_score": 0.0,
          "conditional_clarity": 0.0,
          "ambiguity_score": 0.4,
          "overall_clarity": 0.0
        },
        "actionability": {
          "action_verb_density": 0.03636363636363636,
          "instruction_quality": 0.75,
          "overall_actionability": 0.3931818181818182
        },
        "completeness": {
          "completeness_score": 0.8,
          "missing_elements": [
            "error handling"
          ]
        },
        "usability": {
          "navigation_ease": 0.3333333333333333,
          "information_findability": 0.45606060606060606,
          "consistency_score": 1.0,
          "user_friendliness": 0.5111111111111111
        },
        "accessibility": {
          "plain_language_score": 0.8090909090909091,
          "technical_jargon_ratio": 0.013636363636363636,
          "international_friendly": 1.0
        }
      },
      "system_info": {
        "cpu": {
          "physical_cores": 12,
          "logical_cores": 24,
          "max_frequency": 0.0,
          "cpu_model": "13th Gen Intel(R) Core(TM) i7-13700HX"
        },
        "memory": {
          "total_gb": 15.460460662841797,
          "available_gb": 6.817024230957031,
          "used_gb": 8.24563980102539,
          "percent": 55.9
        },
        "gpu": [
          {
            "id": 0,
            "name": "NVIDIA RTX 2000 Ada Generation Laptop GPU",
            "utilization": 37.0,
            "memory_used": 3748.0,
            "memory_total": 8188.0,
            "temperature": 54.0,
            "driver_version": "538.92",
            "compute_capability": "(8, 9)",
            "pcie_link_width": 8,
            "pcie_link_gen": 4
          }
        ]
      }
    }
  },
  "performance": {
    "use_case_generation_detailed": {
      "total_time": 398.3556411266327,
      "cpu": {
        "mean_percent": 12.813692946058092,
        "max_percent": 25.9,
        "min_percent": 4.7,
        "std_percent": 4.9382094010167785
      },
      "memory": {
        "mean_mb": 8877.319599325727,
        "max_mb": 9627.76171875,
        "min_mb": 8193.69921875,
        "peak_mb": 1434.0625
      },
      "gpu": {
        "mean_percent": 74.4460580912863,
        "max_percent": 97,
        "mean_memory_mb": 7278.058091286307,
        "max_memory_mb": 7723.0,
        "peak_memory_mb": 4893.0,
        "mean_temperature": 56.86721991701245,
        "max_temperature": 59.0,
        "mean_power_watts": 27.83458091286307,
        "max_power_watts": 31.305,
        "total_energy_joules": 11088.062325034702
      },
      "efficiency": {
        "cpu_efficiency": 87.1863070539419,
        "memory_efficiency": 43.92626707396552,
        "gpu_efficiency": 25.553941908713696,
        "performance_per_watt": 35.92653336978659
      }
    },
    "test_case_generation_detailed": {
      "total_time": 643.554806470871,
      "cpu": {
        "mean_percent": 13.482375,
        "max_percent": 27.8,
        "min_percent": 5.2,
        "std_percent": 5.044254341265417
      },
      "memory": {
        "mean_mb": 8245.78740234375,
        "max_mb": 9508.97265625,
        "min_mb": 7500.7109375,
        "peak_mb": 2008.26171875
      },
      "gpu": {
        "mean_percent": 80.32875,
        "max_percent": 100,
        "mean_memory_mb": 7564.295,
        "max_memory_mb": 7710.0,
        "peak_memory_mb": 4163.0,
        "mean_temperature": 57.39875,
        "max_temperature": 59.0,
        "mean_power_watts": 28.78654375,
        "max_power_watts": 32.301,
        "total_energy_joules": 18525.71859199651
      },
      "efficiency": {
        "cpu_efficiency": 86.517625,
        "memory_efficiency": 47.91535041737121,
        "gpu_efficiency": 19.67125,
        "performance_per_watt": 34.73845310102572
      }
    },
    "use_case_generation": {
      "total_time": 397.18748450279236,
      "memory_used": 225.40234375,
      "avg_time_per_file": 397.18748450279236
    },
    "test_case_generation": {
      "total_time": 642.331743478775,
      "memory_used": -165.87109375
    },
    "total_time": 1039.5192279815674,
    "total_memory": 59.53125,
    "files_per_second": 0.0025177026946149148
  },
  "llm_evaluation": {
    "use_case_evaluations": [
      {
        "file": "example_login_use_case.txt",
        "evaluation": {
          "completeness": 8,
          "clarity": 9,
          "testability": 7,
          "technical_accuracy": 9,
          "structure": 8,
          "overall_score": 8,
          "strengths": [
            "Clear and concise use case",
            "Well-structured main flow",
            "Alternative flow clearly defined"
          ],
          "weaknesses": [
            "Missing postconditions for unsuccessful login"
          ],
          "suggestions": [
            "Include postconditions for unsuccessful login",
            "Add more details to the actors and preconditions"
          ],
          "evaluated_model": "Falcon3-7B-Base",
          "content_type": "use_case"
        }
      }
    ],
    "test_case_evaluations": [
      {
        "file": "example_login_use_case.robot",
        "evaluation": {
          "syntax_correctness": 9,
          "test_coverage": 8,
          "best_practices": 7,
          "maintainability": 9,
          "executability": 9,
          "overall_score": 8,
          "strengths": [
            "Clear structure",
            "Use of libraries and keywords",
            "Good test coverage"
          ],
          "weaknesses": [
            "Lack of negative testing"
          ],
          "suggestions": [
            "Add negative testing cases to cover edge cases"
          ],
          "evaluated_model": "Falcon3-7B-Base",
          "content_type": "test_case"
        }
      }
    ],
    "summary": {
      "avg_use_case_score": 8.0,
      "avg_test_case_score": 8.0
    }
  }
}