# Comprehensive LLM Evaluation Report
**Generated:** 2025-06-20T13:48:04.482767
**Models:** Meta-Llama-3-8B-Instruct, mistral

**LLM Evaluator:** gemma_7b_it_4bit
**Evaluator Selection:** Selected as neutral evaluator (not in evaluated models: ['Meta-Llama-3-8B-Instruct', 'mistral'])

## Executive Summary

## Combined Evaluation Results

| Model | BLEU | ROUGE-L | BERTScore | METEOR | LLM Score | Overall |
|-------|------|---------|-----------|---------|-----------|---------|

## Robot Framework Dryrun Analysis

**Overall Success Rate:** 0.0%

| Model | Success Rate | Failed Tests | Most Common Error |
|-------|--------------|--------------|-------------------|
| Meta-Llama-3-8B-Instruct | 0.0% | 2/2 | None |
| mistral | 0.0% | 2/2 | None |

Overall recommendation: **Meta-Llama-3-8B-Instruct** (best in 1 metrics)

### Key Findings

- **Quality Perplexity**: Meta-Llama-3-8B-Instruct (Score: 12.1960)

## Performance Analysis

| Model | Total Time (s) | Memory (MB) | Files/Second |
|-------|----------------|-------------|--------------|
| Meta-Llama-3-8B-Instruct | 1407.98 | 1599.28 | 0.00 |
| mistral | 1298.44 | -52.02 | 0.01 |

## Extended Analysis

### Consistency Analysis

### Quality vs Performance Trade-offs

**Meta-Llama-3-8B-Instruct:**
- Quality Score: 0.00%
- Speed-Quality Ratio: 0.000
- Efficiency Score: 0.000

**mistral:**
- Quality Score: 0.00%
- Speed-Quality Ratio: 0.000
- Efficiency Score: 0.000

### Model Rankings

1. **mistral** (Score: 0.500)
2. **Meta-Llama-3-8B-Instruct** (Score: 0.000)

## Detailed Recommendations

- Overall recommendation: **Meta-Llama-3-8B-Instruct** (best in 1 metrics)
- 
**Extended Metrics Insights:**

## Artifacts Generated

The following files have been generated:
- Individual model results (JSON)
- Comparison report (JSON)
- Metric comparison charts (PNG)
- Quality metrics heatmap (PNG)
- UX metrics radar chart (HTML)
- Comprehensive dashboard (HTML)
