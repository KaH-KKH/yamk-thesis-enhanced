{
  "timestamp": "2025-06-20T20:32:11.869124",
  "models": [
    "Meta-Llama-3-8B-Instruct",
    "Falcon3-7B-Base",
    "gemma_7b_it_4bit"
  ],
  "summary": {
    "best_scores": {
      "quality_perplexity": {
        "model": "Falcon3-7B-Base",
        "value": 8.356622219085693
      }
    }
  },
  "detailed_metrics": {
    "standard": {
      "use_case_metrics": {
        "Meta-Llama-3-8B-Instruct": {
          "custom": {
            "completeness": 1.0,
            "avg_length": 305.0,
            "avg_steps": 29.0
          }
        },
        "Falcon3-7B-Base": {
          "custom": {
            "completeness": 1.0,
            "avg_length": 541.0,
            "avg_steps": 97.5
          }
        },
        "gemma_7b_it_4bit": {
          "custom": {
            "completeness": 1.0,
            "avg_length": 161.5,
            "avg_steps": 15.0
          }
        }
      },
      "test_case_metrics": {
        "Meta-Llama-3-8B-Instruct": {
          "syntax_validity": {
            "valid_count": 2,
            "total_count": 2,
            "validity_rate": 1.0
          },
          "keyword_coverage": {
            "keyword_counts": {
              "New Browser": 2,
              "New Page": 0,
              "Go To": 2,
              "Click": 18,
              "Type Text": 4,
              "Get Text": 3,
              "Wait For Elements State": 5,
              "Take Screenshot": 2
            },
            "total_keywords": 36,
            "unique_keywords_used": 7,
            "coverage_rate": 0.875
          }
        },
        "Falcon3-7B-Base": {
          "syntax_validity": {
            "valid_count": 2,
            "total_count": 2,
            "validity_rate": 1.0
          },
          "keyword_coverage": {
            "keyword_counts": {
              "New Browser": 4,
              "New Page": 2,
              "Go To": 2,
              "Click": 3,
              "Type Text": 6,
              "Get Text": 0,
              "Wait For Elements State": 3,
              "Take Screenshot": 4
            },
            "total_keywords": 24,
            "unique_keywords_used": 7,
            "coverage_rate": 0.875
          }
        },
        "gemma_7b_it_4bit": {
          "syntax_validity": {
            "valid_count": 2,
            "total_count": 2,
            "validity_rate": 1.0
          },
          "keyword_coverage": {
            "keyword_counts": {
              "New Browser": 2,
              "New Page": 0,
              "Go To": 2,
              "Click": 3,
              "Type Text": 5,
              "Get Text": 5,
              "Wait For Elements State": 2,
              "Take Screenshot": 2
            },
            "total_keywords": 21,
            "unique_keywords_used": 7,
            "coverage_rate": 0.875
          }
        }
      }
    },
    "extended": {
      "quality": {
        "Meta-Llama-3-8B-Instruct": {
          "perplexity": {
            "mean_perplexity": 14.54827070236206,
            "min_perplexity": 6.235852241516113,
            "max_perplexity": 22.860689163208008,
            "std_perplexity": 8.312418460845947
          },
          "diversity": {
            "self_bleu": 6.932862538350088,
            "distinct_1": 0.2421185372005044,
            "distinct_2": 0.4943109987357775,
            "distinct_3": 0.6210392902408112,
            "vocabulary_size": 192,
            "token_type_ratio": 0.2421185372005044
          },
          "coherence": {
            "mean_coherence": 0.152695432305336,
            "min_coherence": 0.10120484977960587,
            "max_coherence": 0.20418602228164673,
            "std_coherence": 0.05149058625102043
          }
        },
        "Falcon3-7B-Base": {
          "perplexity": {
            "mean_perplexity": 8.356622219085693,
            "min_perplexity": 7.9900407791137695,
            "max_perplexity": 8.723203659057617,
            "std_perplexity": 0.36658143997192383
          },
          "diversity": {
            "self_bleu": 20.887922987885407,
            "distinct_1": 0.21367521367521367,
            "distinct_2": 0.4878209348255431,
            "distinct_3": 0.6249176005273567,
            "vocabulary_size": 325,
            "token_type_ratio": 0.21367521367521367
          },
          "coherence": {
            "mean_coherence": 0.24678495526313782,
            "min_coherence": 0.245150625705719,
            "max_coherence": 0.24841928482055664,
            "std_coherence": 0.0016343295574188232
          }
        },
        "gemma_7b_it_4bit": {
          "perplexity": {
            "mean_perplexity": 16.640353202819824,
            "min_perplexity": 15.719955444335938,
            "max_perplexity": 17.56075096130371,
            "std_perplexity": 0.9203977584838867
          },
          "diversity": {
            "self_bleu": 32.76444510004594,
            "distinct_1": 0.28028503562945367,
            "distinct_2": 0.6181384248210023,
            "distinct_3": 0.7817745803357314,
            "vocabulary_size": 118,
            "token_type_ratio": 0.28028503562945367
          },
          "coherence": {
            "mean_coherence": 0.15526726841926575,
            "min_coherence": 0.1447303295135498,
            "max_coherence": 0.16580422222614288,
            "std_coherence": 0.01053694635629654
          }
        }
      },
      "user_experience": {
        "Meta-Llama-3-8B-Instruct": {
          "readability": {
            "flesch_reading_ease": {
              "score": 58.491997920432226,
              "interpretation": "Fairly Difficult"
            },
            "flesch_kincaid_grade": {
              "score": 7.432613696469151,
              "interpretation": "Grade level: 7.4"
            },
            "gunning_fog": {
              "score": 9.440680526615155,
              "interpretation": "Years of education needed: 9.4"
            },
            "smog_index": {
              "score": 9.711362327904588,
              "interpretation": "Score: 9.71"
            },
            "automated_readability_index": {
              "score": 6.971252481524116,
              "interpretation": "Score: 6.97"
            },
            "coleman_liau_index": {
              "score": 8.455761092759577,
              "interpretation": "Score: 8.46"
            },
            "linsear_write_formula": {
              "score": 5.1454545454545455,
              "interpretation": "Score: 5.15"
            },
            "dale_chall_readability_score": {
              "score": 12.030878605459193,
              "interpretation": "Score: 12.03"
            },
            "avg_sentence_length": 7.6165845648604265,
            "avg_word_length": 3.7592943997583173,
            "syllables_per_word": 1.194304406933273,
            "overall_readability": "Moderate - Requires some effort"
          },
          "clarity": {
            "specificity_score": 0.0030959752321981426,
            "vagueness_score": 0.0,
            "structure_score": 0.0,
            "conditional_clarity": 0.0007739938080495357,
            "ambiguity_score": 0.20181704318731572,
            "overall_clarity": 0.001238390092879257
          },
          "actionability": {
            "action_verb_density": 0.0,
            "step_clarity": 0.19878048780487806,
            "executable_steps": 0.29878048780487804,
            "overall_actionability": 0.16585365853658537
          },
          "completeness": {
            "completeness_score": 1.0,
            "missing_elements": []
          },
          "usability": {
            "navigation_ease": 1.0,
            "information_findability": 0.7752838513147791,
            "consistency_score": 1.0,
            "user_friendliness": 0.590205175098079
          },
          "accessibility": {
            "plain_language_score": 0.8736178681999115,
            "technical_jargon_ratio": 0.01778079652913797,
            "international_friendly": 1.0
          }
        },
        "Falcon3-7B-Base": {
          "readability": {
            "flesch_reading_ease": {
              "score": 63.17659664110357,
              "interpretation": "Standard"
            },
            "flesch_kincaid_grade": {
              "score": 6.521361344902944,
              "interpretation": "Grade level: 6.5"
            },
            "gunning_fog": {
              "score": 7.902131873990847,
              "interpretation": "Years of education needed: 7.9"
            },
            "smog_index": {
              "score": 8.702606715757494,
              "interpretation": "Score: 8.70"
            },
            "automated_readability_index": {
              "score": 7.605882699216412,
              "interpretation": "Score: 7.61"
            },
            "coleman_liau_index": {
              "score": 8.658074218938804,
              "interpretation": "Score: 8.66"
            },
            "linsear_write_formula": {
              "score": 4.0874125874125875,
              "interpretation": "Score: 4.09"
            },
            "dale_chall_readability_score": {
              "score": 12.96393359103772,
              "interpretation": "Score: 12.96"
            },
            "avg_sentence_length": 7.423980995248812,
            "avg_word_length": 3.5969804811815735,
            "syllables_per_word": 1.027061855670103,
            "overall_readability": "Moderate - Requires some effort"
          },
          "clarity": {
            "specificity_score": 0.0033467202141900937,
            "vagueness_score": 0.0,
            "structure_score": 0.002677376171352075,
            "conditional_clarity": 0.0032766725818000686,
            "ambiguity_score": 0.16798256281782614,
            "overall_clarity": 0.0024096385542168677
          },
          "actionability": {
            "action_verb_density": 0.011697954609134212,
            "step_clarity": 0.11470037453183521,
            "executable_steps": 0.18345371856607812,
            "overall_actionability": 0.10328401590234919
          },
          "completeness": {
            "completeness_score": 1.0,
            "missing_elements": []
          },
          "usability": {
            "navigation_ease": 1.0,
            "information_findability": 0.7552534517855898,
            "consistency_score": 1.0,
            "user_friendliness": 0.48551774041936263
          },
          "accessibility": {
            "plain_language_score": 0.8993415522555338,
            "technical_jargon_ratio": 0.002583979328165375,
            "international_friendly": 0.9833333333333334
          }
        },
        "gemma_7b_it_4bit": {
          "readability": {
            "flesch_reading_ease": {
              "score": 61.06592629919102,
              "interpretation": "Standard"
            },
            "flesch_kincaid_grade": {
              "score": 7.16816906622789,
              "interpretation": "Grade level: 7.2"
            },
            "gunning_fog": {
              "score": 8.188855066502125,
              "interpretation": "Years of education needed: 8.2"
            },
            "smog_index": {
              "score": 9.026937267102872,
              "interpretation": "Score: 9.03"
            },
            "automated_readability_index": {
              "score": 7.048754831478044,
              "interpretation": "Score: 7.05"
            },
            "coleman_liau_index": {
              "score": 8.479921842863023,
              "interpretation": "Score: 8.48"
            },
            "linsear_write_formula": {
              "score": 4.713636363636364,
              "interpretation": "Score: 4.71"
            },
            "dale_chall_readability_score": {
              "score": 12.36861979706568,
              "interpretation": "Score: 12.37"
            },
            "avg_sentence_length": 8.066666666666666,
            "avg_word_length": 3.7047131147540986,
            "syllables_per_word": 1.1337295081967214,
            "overall_readability": "Moderate - Requires some effort"
          },
          "clarity": {
            "specificity_score": 0.009601350118591498,
            "vagueness_score": 0.0,
            "structure_score": 0.0,
            "conditional_clarity": 0.009601350118591498,
            "ambiguity_score": 0.21341222615145766,
            "overall_clarity": 0.0038405400474365993
          },
          "actionability": {
            "action_verb_density": 0.006955847473088852,
            "step_clarity": 0.23717948717948717,
            "executable_steps": 0.27564102564102566,
            "overall_actionability": 0.17325878676453388
          },
          "completeness": {
            "completeness_score": 1.0,
            "missing_elements": []
          },
          "usability": {
            "navigation_ease": 1.0,
            "information_findability": 0.802622950819672,
            "consistency_score": 1.0,
            "user_friendliness": 0.7642175259381141
          },
          "accessibility": {
            "plain_language_score": 0.8958561393906221,
            "technical_jargon_ratio": 0.005291005291005291,
            "international_friendly": 1.0
          }
        }
      },
      "robot_framework": {
        "Meta-Llama-3-8B-Instruct": {
          "overall_quality": {
            "total_tests": 7,
            "documentation_coverage": 0.14285714285714285,
            "tag_coverage": 0.14285714285714285,
            "verification_coverage": 0.42857142857142855
          },
          "keyword_analysis": {
            "total_keywords_used": 85,
            "unique_keywords": 10,
            "custom_keywords_defined": 3,
            "keyword_reuse_ratio": 0.3,
            "browser_keyword_usage": {
              "interaction": 11
            },
            "most_used_keywords": {
              "...": 50,
              "Click": 11,
              "Wait": 5,
              "New": 4,
              "Type": 4,
              "Get": 3,
              "Set": 2,
              "Take": 2,
              "Close": 2,
              "Go": 2
            }
          },
          "structure_analysis": {
            "avg_test_length": 5.714285714285714,
            "max_test_length": 18,
            "min_test_length": 2,
            "avg_complexity": 1.1428571428571428,
            "max_complexity": 2.0
          },
          "best_practices": {
            "selector_usage": {
              "id": 8,
              "css": 4,
              "xpath": 0,
              "text": 13,
              "data_test": 0,
              "aria": 0
            },
            "best_selector_ratio": 0.32,
            "explicit_wait_usage": 5,
            "implicit_wait_usage": 0,
            "wait_strategy_score": 1.0,
            "error_handling_present": false,
            "screenshot_usage": 2,
            "data_driven_testing": false,
            "template_usage": 0,
            "loop_usage": 0
          },
          "individual_files": {
            "Basic_Auth_PASS_use_case.robot": {
              "syntax_valid": true,
              "sections": [
                "Settings",
                "Variables",
                "Keywords"
              ],
              "test_count": 1,
              "keyword_count": 3,
              "documentation_present": true,
              "tags_present": true,
              "setup_teardown": {
                "test_setup": true,
                "test_teardown": true,
                "suite_setup": false,
                "suite_teardown": false
              },
              "line_count": 93,
              "non_empty_lines": 85
            },
            "Basic_Auth_FAIL_use_case.robot": {
              "syntax_valid": true,
              "sections": [
                "Settings",
                "Variables",
                "Keywords"
              ],
              "test_count": 1,
              "keyword_count": 3,
              "documentation_present": true,
              "tags_present": true,
              "setup_teardown": {
                "test_setup": true,
                "test_teardown": true,
                "suite_setup": false,
                "suite_teardown": false
              },
              "line_count": 56,
              "non_empty_lines": 48
            }
          }
        },
        "Falcon3-7B-Base": {
          "overall_quality": {
            "total_tests": 8,
            "documentation_coverage": 0.25,
            "tag_coverage": 0.25,
            "verification_coverage": 0.375
          },
          "keyword_analysis": {
            "total_keywords_used": 31,
            "unique_keywords": 9,
            "custom_keywords_defined": 3,
            "keyword_reuse_ratio": 0.3333333333333333,
            "browser_keyword_usage": {
              "interaction": 3
            },
            "most_used_keywords": {
              "New": 8,
              "Type": 6,
              "Take": 4,
              "Click": 3,
              "Wait": 3,
              "Set": 2,
              "Close": 2,
              "Go": 2,
              "Log": 1
            }
          },
          "structure_analysis": {
            "avg_test_length": 4.625,
            "max_test_length": 9,
            "min_test_length": 2,
            "avg_complexity": 1.0,
            "max_complexity": 1
          },
          "best_practices": {
            "selector_usage": {
              "id": 6,
              "css": 5,
              "xpath": 0,
              "text": 1,
              "data_test": 0,
              "aria": 0
            },
            "best_selector_ratio": 0.5,
            "explicit_wait_usage": 3,
            "implicit_wait_usage": 0,
            "wait_strategy_score": 1.0,
            "error_handling_present": false,
            "screenshot_usage": 4,
            "data_driven_testing": false,
            "template_usage": 0,
            "loop_usage": 0
          },
          "individual_files": {
            "Basic_Auth_PASS_use_case.robot": {
              "syntax_valid": true,
              "sections": [
                "Settings",
                "Variables",
                "Keywords"
              ],
              "test_count": 1,
              "keyword_count": 3,
              "documentation_present": true,
              "tags_present": true,
              "setup_teardown": {
                "test_setup": true,
                "test_teardown": true,
                "suite_setup": false,
                "suite_teardown": false
              },
              "line_count": 43,
              "non_empty_lines": 36
            },
            "Basic_Auth_FAIL_use_case.robot": {
              "syntax_valid": true,
              "sections": [
                "Settings",
                "Variables",
                "Keywords"
              ],
              "test_count": 1,
              "keyword_count": 3,
              "documentation_present": true,
              "tags_present": true,
              "setup_teardown": {
                "test_setup": true,
                "test_teardown": true,
                "suite_setup": false,
                "suite_teardown": false
              },
              "line_count": 46,
              "non_empty_lines": 39
            }
          }
        },
        "gemma_7b_it_4bit": {
          "overall_quality": {
            "total_tests": 7,
            "documentation_coverage": 0.14285714285714285,
            "tag_coverage": 0.14285714285714285,
            "verification_coverage": 0.42857142857142855
          },
          "keyword_analysis": {
            "total_keywords_used": 43,
            "unique_keywords": 11,
            "custom_keywords_defined": 3,
            "keyword_reuse_ratio": 0.2727272727272727,
            "browser_keyword_usage": {
              "interaction": 3
            },
            "most_used_keywords": {
              "...": 9,
              "Log": 7,
              "Get": 5,
              "Type": 5,
              "New": 4,
              "Click": 3,
              "Set": 2,
              "Take": 2,
              "Close": 2,
              "Go": 2
            }
          },
          "structure_analysis": {
            "avg_test_length": 5.142857142857143,
            "max_test_length": 14,
            "min_test_length": 2,
            "avg_complexity": 1.1428571428571428,
            "max_complexity": 2.0
          },
          "best_practices": {
            "selector_usage": {
              "id": 4,
              "css": 4,
              "xpath": 0,
              "text": 1,
              "data_test": 0,
              "aria": 0
            },
            "best_selector_ratio": 0.4444444444444444,
            "explicit_wait_usage": 2,
            "implicit_wait_usage": 0,
            "wait_strategy_score": 1.0,
            "error_handling_present": false,
            "screenshot_usage": 2,
            "data_driven_testing": false,
            "template_usage": 0,
            "loop_usage": 0
          },
          "individual_files": {
            "Basic_Auth_PASS_use_case.robot": {
              "syntax_valid": true,
              "sections": [
                "Settings",
                "Variables",
                "Keywords"
              ],
              "test_count": 1,
              "keyword_count": 3,
              "documentation_present": true,
              "tags_present": true,
              "setup_teardown": {
                "test_setup": true,
                "test_teardown": true,
                "suite_setup": false,
                "suite_teardown": false
              },
              "line_count": 55,
              "non_empty_lines": 47
            },
            "Basic_Auth_FAIL_use_case.robot": {
              "syntax_valid": true,
              "sections": [
                "Settings",
                "Variables",
                "Keywords"
              ],
              "test_count": 1,
              "keyword_count": 3,
              "documentation_present": true,
              "tags_present": true,
              "setup_teardown": {
                "test_setup": true,
                "test_teardown": true,
                "suite_setup": false,
                "suite_teardown": false
              },
              "line_count": 52,
              "non_empty_lines": 44
            }
          }
        }
      },
      "test_case_ux": {
        "Meta-Llama-3-8B-Instruct": {
          "readability": {
            "flesch_reading_ease": {
              "score": 30.74139808612358,
              "interpretation": "Difficult"
            },
            "flesch_kincaid_grade": {
              "score": 12.316711648100124,
              "interpretation": "Grade level: 12.3"
            },
            "gunning_fog": {
              "score": 12.622032881973247,
              "interpretation": "Years of education needed: 12.6"
            },
            "smog_index": {
              "score": 12.293314748370811,
              "interpretation": "Score: 12.29"
            },
            "automated_readability_index": {
              "score": 15.901293552055439,
              "interpretation": "Score: 15.90"
            },
            "coleman_liau_index": {
              "score": 18.997895441718086,
              "interpretation": "Score: 19.00"
            },
            "linsear_write_formula": {
              "score": 8.825396825396826,
              "interpretation": "Score: 8.83"
            },
            "dale_chall_readability_score": {
              "score": 12.779984184314507,
              "interpretation": "Score: 12.78"
            },
            "avg_sentence_length": 35.52840909090909,
            "avg_word_length": 4.522060531529686,
            "syllables_per_word": 1.1869827605839083,
            "overall_readability": "Poor - Difficult to understand"
          },
          "clarity": {
            "specificity_score": 0.003022021816856824,
            "vagueness_score": 0.0,
            "structure_score": 0.0,
            "conditional_clarity": 0.007631345221015236,
            "ambiguity_score": 0.38079311916154024,
            "overall_clarity": 0.0012088087267427298
          },
          "actionability": {
            "action_verb_density": 0.03350185602696363,
            "instruction_quality": 0.75,
            "overall_actionability": 0.3917509280134818
          },
          "completeness": {
            "completeness_score": 1.0,
            "missing_elements": [
              "error handling"
            ]
          },
          "usability": {
            "navigation_ease": 0.3333333333333333,
            "information_findability": 0.6048598301109062,
            "consistency_score": 1.0,
            "user_friendliness": 0.35543168964298333
          },
          "accessibility": {
            "plain_language_score": 0.8343535788299059,
            "technical_jargon_ratio": 0.021718931475029037,
            "international_friendly": 1.0
          }
        },
        "Falcon3-7B-Base": {
          "readability": {
            "flesch_reading_ease": {
              "score": 0.09946373200443759,
              "interpretation": "Very Difficult"
            },
            "flesch_kincaid_grade": {
              "score": 21.08749363233666,
              "interpretation": "Grade level: 21.1"
            },
            "gunning_fog": {
              "score": 21.05136212624585,
              "interpretation": "Years of education needed: 21.1"
            },
            "smog_index": {
              "score": 18.600854968066407,
              "interpretation": "Score: 18.60"
            },
            "automated_readability_index": {
              "score": 29.380233880778587,
              "interpretation": "Score: 29.38"
            },
            "coleman_liau_index": {
              "score": 23.69705149501661,
              "interpretation": "Score: 23.70"
            },
            "linsear_write_formula": {
              "score": 26.5,
              "interpretation": "Score: 26.50"
            },
            "dale_chall_readability_score": {
              "score": 15.874773457918053,
              "interpretation": "Score: 15.87"
            },
            "avg_sentence_length": 142.66666666666666,
            "avg_word_length": 4.341263262599469,
            "syllables_per_word": 1.1302221485411141,
            "overall_readability": "Poor - Difficult to understand"
          },
          "clarity": {
            "specificity_score": 0.0,
            "vagueness_score": 0.0,
            "structure_score": 0.0,
            "conditional_clarity": 0.0,
            "ambiguity_score": 0.39,
            "overall_clarity": 0.0
          },
          "actionability": {
            "action_verb_density": 0.03406830238726791,
            "instruction_quality": 0.75,
            "overall_actionability": 0.39203415119363394
          },
          "completeness": {
            "completeness_score": 0.8,
            "missing_elements": [
              "error handling"
            ]
          },
          "usability": {
            "navigation_ease": 0.3333333333333333,
            "information_findability": 0.11524646330680813,
            "consistency_score": 1.0,
            "user_friendliness": 0.5111111111111111
          },
          "accessibility": {
            "plain_language_score": 0.7979940318302388,
            "technical_jargon_ratio": 0.013677055702917773,
            "international_friendly": 1.0
          }
        },
        "gemma_7b_it_4bit": {
          "readability": {
            "flesch_reading_ease": {
              "score": 36.74787400679817,
              "interpretation": "Difficult"
            },
            "flesch_kincaid_grade": {
              "score": 11.689034774994527,
              "interpretation": "Grade level: 11.7"
            },
            "gunning_fog": {
              "score": 11.354334485603836,
              "interpretation": "Years of education needed: 11.4"
            },
            "smog_index": {
              "score": 11.72581664058449,
              "interpretation": "Score: 11.73"
            },
            "automated_readability_index": {
              "score": 15.48826849673624,
              "interpretation": "Score: 15.49"
            },
            "coleman_liau_index": {
              "score": 17.25866185070519,
              "interpretation": "Score: 17.26"
            },
            "linsear_write_formula": {
              "score": 7.848214285714286,
              "interpretation": "Score: 7.85"
            },
            "dale_chall_readability_score": {
              "score": 13.793991139785568,
              "interpretation": "Score: 13.79"
            },
            "avg_sentence_length": 37.611111111111114,
            "avg_word_length": 4.014174849540703,
            "syllables_per_word": 1.0546800760215396,
            "overall_readability": "Poor - Difficult to understand"
          },
          "clarity": {
            "specificity_score": 0.0,
            "vagueness_score": 0.0,
            "structure_score": 0.0,
            "conditional_clarity": 0.0,
            "ambiguity_score": 0.34031746031746035,
            "overall_clarity": 0.0
          },
          "actionability": {
            "action_verb_density": 0.027043078872347165,
            "instruction_quality": 0.75,
            "overall_actionability": 0.38852153943617357
          },
          "completeness": {
            "completeness_score": 0.8,
            "missing_elements": [
              "error handling"
            ]
          },
          "usability": {
            "navigation_ease": 0.3333333333333333,
            "information_findability": 0.4488438390877415,
            "consistency_score": 1.0,
            "user_friendliness": 0.35641570069459644
          },
          "accessibility": {
            "plain_language_score": 0.8536585365853658,
            "technical_jargon_ratio": 0.015323091542603738,
            "international_friendly": 1.0
          }
        }
      },
      "system_info": {
        "Meta-Llama-3-8B-Instruct": {
          "cpu": {
            "physical_cores": 12,
            "logical_cores": 24,
            "max_frequency": 0.0,
            "cpu_model": "13th Gen Intel(R) Core(TM) i7-13700HX"
          },
          "memory": {
            "total_gb": 15.460460662841797,
            "available_gb": 9.069473266601562,
            "used_gb": 6.000999450683594,
            "percent": 41.3
          },
          "gpu": [
            {
              "id": 0,
              "name": "NVIDIA RTX 2000 Ada Generation Laptop GPU",
              "utilization": 0.0,
              "memory_used": 3340.0,
              "memory_total": 8188.0,
              "temperature": 52.0,
              "driver_version": "538.92",
              "compute_capability": "(8, 9)",
              "pcie_link_width": 8,
              "pcie_link_gen": 4
            }
          ]
        },
        "Falcon3-7B-Base": {
          "cpu": {
            "physical_cores": 12,
            "logical_cores": 24,
            "max_frequency": 0.0,
            "cpu_model": "13th Gen Intel(R) Core(TM) i7-13700HX"
          },
          "memory": {
            "total_gb": 15.460460662841797,
            "available_gb": 9.249004364013672,
            "used_gb": 5.8147430419921875,
            "percent": 40.2
          },
          "gpu": [
            {
              "id": 0,
              "name": "NVIDIA RTX 2000 Ada Generation Laptop GPU",
              "utilization": 5.0,
              "memory_used": 3580.0,
              "memory_total": 8188.0,
              "temperature": 55.0,
              "driver_version": "538.92",
              "compute_capability": "(8, 9)",
              "pcie_link_width": 8,
              "pcie_link_gen": 4
            }
          ]
        },
        "gemma_7b_it_4bit": {
          "cpu": {
            "physical_cores": 12,
            "logical_cores": 24,
            "max_frequency": 0.0,
            "cpu_model": "13th Gen Intel(R) Core(TM) i7-13700HX"
          },
          "memory": {
            "total_gb": 15.460460662841797,
            "available_gb": 9.438499450683594,
            "used_gb": 5.6251983642578125,
            "percent": 39.0
          },
          "gpu": [
            {
              "id": 0,
              "name": "NVIDIA RTX 2000 Ada Generation Laptop GPU",
              "utilization": 24.0,
              "memory_used": 3000.0,
              "memory_total": 8188.0,
              "temperature": 56.0,
              "driver_version": "538.92",
              "compute_capability": "(8, 9)",
              "pcie_link_width": 8,
              "pcie_link_gen": 4
            }
          ]
        }
      }
    }
  },
  "performance_comparison": {
    "Meta-Llama-3-8B-Instruct": {
      "use_case_generation_detailed": {
        "total_time": 541.391105890274,
        "cpu": {
          "mean_percent": 4.110142857142858,
          "max_percent": 6.6,
          "min_percent": 0.0,
          "std_percent": 0.5608641110112218
        },
        "memory": {
          "mean_mb": 5929.0906640625,
          "max_mb": 6071.95703125,
          "min_mb": 4439.40234375,
          "peak_mb": 1632.5546875
        },
        "gpu": {
          "mean_percent": 79.07857142857142,
          "max_percent": 100,
          "mean_memory_mb": 7666.96,
          "max_memory_mb": 7758.0,
          "peak_memory_mb": 5248.0,
          "mean_temperature": 55.56,
          "max_temperature": 59.0,
          "mean_power_watts": 28.75009285714286,
          "max_power_watts": 31.408,
          "total_energy_joules": 15565.044566376642
        },
        "efficiency": {
          "cpu_efficiency": 95.88985714285714,
          "memory_efficiency": 62.548802859802706,
          "gpu_efficiency": 20.921428571428578,
          "performance_per_watt": 34.78249635467016
        }
      },
      "test_case_generation_detailed": {
        "total_time": 916.7396833896637,
        "cpu": {
          "mean_percent": 4.176694915254237,
          "max_percent": 7.9,
          "min_percent": 0.4,
          "std_percent": 0.4223512777754462
        },
        "memory": {
          "mean_mb": 6093.1125960010595,
          "max_mb": 6228.87890625,
          "min_mb": 6049.73828125,
          "peak_mb": 179.140625
        },
        "gpu": {
          "mean_percent": 87.18389830508474,
          "max_percent": 100,
          "mean_memory_mb": 7530.985593220339,
          "max_memory_mb": 7629.0,
          "peak_memory_mb": 5119.0,
          "mean_temperature": 57.51186440677966,
          "max_temperature": 59.0,
          "mean_power_watts": 29.522448305084747,
          "max_power_watts": 31.051,
          "total_energy_joules": 27064.399912091103
        },
        "efficiency": {
          "cpu_efficiency": 95.82330508474577,
          "memory_efficiency": 61.512755672064465,
          "gpu_efficiency": 12.816101694915261,
          "performance_per_watt": 33.87252946185248
        }
      },
      "use_case_generation": {
        "total_time": 539.1964592933655,
        "memory_used": 1817.07421875,
        "avg_time_per_file": 269.59822964668274
      },
      "test_case_generation": {
        "total_time": 915.5383093357086,
        "memory_used": -250.484375
      },
      "total_time": 1454.734768629074,
      "total_memory": 1566.58984375,
      "files_per_second": 0.0037092231700131435
    },
    "Falcon3-7B-Base": {
      "use_case_generation_detailed": {
        "total_time": 1144.046217918396,
        "cpu": {
          "mean_percent": 4.1969429347826095,
          "max_percent": 8.3,
          "min_percent": 0.4,
          "std_percent": 0.4509321890649029
        },
        "memory": {
          "mean_mb": 6536.1225214419155,
          "max_mb": 6752.5,
          "min_mb": 6175.05859375,
          "peak_mb": 577.44140625
        },
        "gpu": {
          "mean_percent": 83.22350543478261,
          "max_percent": 99,
          "mean_memory_mb": 7623.645380434783,
          "max_memory_mb": 7797.0,
          "peak_memory_mb": 5047.0,
          "mean_temperature": 56.55774456521739,
          "max_temperature": 60.0,
          "mean_power_watts": 30.195857336956518,
          "max_power_watts": 60.509,
          "total_energy_joules": 34545.45638314856
        },
        "efficiency": {
          "cpu_efficiency": 95.80305706521739,
          "memory_efficiency": 58.71447630802762,
          "gpu_efficiency": 16.77649456521739,
          "performance_per_watt": 33.11712559908363
        }
      },
      "test_case_generation_detailed": {
        "total_time": 2121.0432493686676,
        "cpu": {
          "mean_percent": 4.1903119266055056,
          "max_percent": 9.4,
          "min_percent": 0.0,
          "std_percent": 0.3636634369335791
        },
        "memory": {
          "mean_mb": 6012.453897649082,
          "max_mb": 6789.1328125,
          "min_mb": 5947.67578125,
          "peak_mb": 841.45703125
        },
        "gpu": {
          "mean_percent": 86.30275229357798,
          "max_percent": 100,
          "mean_memory_mb": 7736.794495412844,
          "max_memory_mb": 7780.0,
          "peak_memory_mb": 4646.0,
          "mean_temperature": 57.11816513761468,
          "max_temperature": 60.0,
          "mean_power_watts": 30.03859926605504,
          "max_power_watts": 42.138,
          "total_energy_joules": 63713.16819375666
        },
        "efficiency": {
          "cpu_efficiency": 95.8096880733945,
          "memory_efficiency": 62.022237645642825,
          "gpu_efficiency": 13.697247706422019,
          "performance_per_watt": 33.29050037063628
        }
      },
      "use_case_generation": {
        "total_time": 1143.028025150299,
        "memory_used": 557.5859375,
        "avg_time_per_file": 571.5140125751495
      },
      "test_case_generation": {
        "total_time": 2119.0078423023224,
        "memory_used": -546.19140625
      },
      "total_time": 3262.0358674526215,
      "total_memory": 11.39453125,
      "files_per_second": 0.0017497383756072088
    },
    "gemma_7b_it_4bit": {
      "use_case_generation_detailed": {
        "total_time": 532.9674556255341,
        "cpu": {
          "mean_percent": 4.1656477438136825,
          "max_percent": 10.5,
          "min_percent": 0.0,
          "std_percent": 0.7415602642750473
        },
        "memory": {
          "mean_mb": 5910.6027167485445,
          "max_mb": 6040.3203125,
          "min_mb": 5795.515625,
          "peak_mb": 244.8046875
        },
        "gpu": {
          "mean_percent": 86.58515283842794,
          "max_percent": 100,
          "mean_memory_mb": 7644.556040756914,
          "max_memory_mb": 7833.0,
          "peak_memory_mb": 5506.0,
          "mean_temperature": 57.65502183406114,
          "max_temperature": 60.0,
          "mean_power_watts": 29.89455458515284,
          "max_power_watts": 33.15,
          "total_energy_joules": 15932.824694307554
        },
        "efficiency": {
          "cpu_efficiency": 95.83435225618632,
          "memory_efficiency": 62.66558227823347,
          "gpu_efficiency": 13.414847161572055,
          "performance_per_watt": 33.45090816294186
        }
      },
      "test_case_generation_detailed": {
        "total_time": 903.9786200523376,
        "cpu": {
          "mean_percent": 4.186550218340612,
          "max_percent": 33.2,
          "min_percent": 0.4,
          "std_percent": 0.9772847481257274
        },
        "memory": {
          "mean_mb": 5841.040154203057,
          "max_mb": 6123.9609375,
          "min_mb": 5758.68359375,
          "peak_mb": 365.27734375
        },
        "gpu": {
          "mean_percent": 87.98078602620087,
          "max_percent": 100,
          "mean_memory_mb": 7627.682096069869,
          "max_memory_mb": 7804.0,
          "peak_memory_mb": 5477.0,
          "mean_temperature": 56.9353711790393,
          "max_temperature": 60.0,
          "mean_power_watts": 29.539950218340614,
          "max_power_watts": 32.873,
          "total_energy_joules": 26703.483434790298
        },
        "efficiency": {
          "cpu_efficiency": 95.81344978165939,
          "memory_efficiency": 63.10497533040234,
          "gpu_efficiency": 12.019213973799125,
          "performance_per_watt": 33.85246056979219
        }
      },
      "use_case_generation": {
        "total_time": 530.8564462661743,
        "memory_used": 168.22265625,
        "avg_time_per_file": 265.42822313308716
      },
      "test_case_generation": {
        "total_time": 902.5324130058289,
        "memory_used": -32.203125
      },
      "total_time": 1433.3888592720032,
      "total_memory": 136.01953125,
      "files_per_second": 0.0037674968705140094
    }
  },
  "recommendations": [
    "Overall recommendation: **Falcon3-7B-Base** (best in 1 metrics)",
    "\n**Extended Metrics Insights:**"
  ],
  "llm_evaluator_info": {
    "enabled": true,
    "model": "mistral",
    "reason": "Selected as neutral evaluator (not in evaluated models: ['Meta-Llama-3-8B-Instruct', 'Falcon3-7B-Base', 'gemma_7b_it_4bit'])"
  },
  "extended_analysis": {
    "consistency": {},
    "trade_offs": {
      "Meta-Llama-3-8B-Instruct": {
        "quality_score": 0,
        "speed_quality_ratio": 0.0,
        "memory_quality_ratio": 0.0,
        "efficiency_score": 0.0
      },
      "Falcon3-7B-Base": {
        "quality_score": 0,
        "speed_quality_ratio": 0.0,
        "memory_quality_ratio": 0.0,
        "efficiency_score": 0.0
      },
      "gemma_7b_it_4bit": {
        "quality_score": 0,
        "speed_quality_ratio": 0.0,
        "memory_quality_ratio": 0.0,
        "efficiency_score": 0.0
      }
    },
    "scalability": {
      "Meta-Llama-3-8B-Instruct": {
        "files_per_second": 0.0037092231700131435,
        "memory_efficiency": 1.2766583467773105,
        "time_complexity": "O(n²) - Quadratic"
      },
      "Falcon3-7B-Base": {
        "files_per_second": 0.0017497383756072088,
        "memory_efficiency": 175.52279739458348,
        "time_complexity": "O(n²) - Quadratic"
      },
      "gemma_7b_it_4bit": {
        "files_per_second": 0.0037674968705140094,
        "memory_efficiency": 14.703770713075443,
        "time_complexity": "O(n²) - Quadratic"
      }
    },
    "robustness": {
      "Meta-Llama-3-8B-Instruct": {
        "error_rate": 0.0,
        "success_rate": 1.0,
        "graceful_failure": false,
        "reliability_score": 100.0
      },
      "Falcon3-7B-Base": {
        "error_rate": 0.0,
        "success_rate": 1.0,
        "graceful_failure": false,
        "reliability_score": 100.0
      },
      "gemma_7b_it_4bit": {
        "error_rate": 0.0,
        "success_rate": 1.0,
        "graceful_failure": false,
        "reliability_score": 100.0
      }
    },
    "statistical_significance": {
      "Meta-Llama-3-8B-Instruct_vs_Falcon3-7B-Base": {
        "model1": "Meta-Llama-3-8B-Instruct",
        "model2": "Falcon3-7B-Base",
        "score_difference": 0.0,
        "effect_size": 0.0,
        "effect_interpretation": "Negligible",
        "winner": "Falcon3-7B-Base"
      },
      "Meta-Llama-3-8B-Instruct_vs_gemma_7b_it_4bit": {
        "model1": "Meta-Llama-3-8B-Instruct",
        "model2": "gemma_7b_it_4bit",
        "score_difference": 0.0,
        "effect_size": 0.0,
        "effect_interpretation": "Negligible",
        "winner": "gemma_7b_it_4bit"
      },
      "Falcon3-7B-Base_vs_gemma_7b_it_4bit": {
        "model1": "Falcon3-7B-Base",
        "model2": "gemma_7b_it_4bit",
        "score_difference": 0.0,
        "effect_size": 0.0,
        "effect_interpretation": "Negligible",
        "winner": "gemma_7b_it_4bit"
      }
    },
    "ranking": [
      {
        "model": "gemma_7b_it_4bit",
        "composite_score": 0.26926457659215947,
        "scores": {
          "completeness": 0.0,
          "validity": 0.0,
          "speed": 1.0,
          "memory": 0.07705830636863793
        },
        "rank": 1
      },
      {
        "model": "Falcon3-7B-Base",
        "composite_score": 0.25,
        "scores": {
          "completeness": 0.0,
          "validity": 0.0,
          "speed": 0.0,
          "memory": 1.0
        },
        "rank": 2
      },
      {
        "model": "Meta-Llama-3-8B-Instruct",
        "composite_score": 0.24345620473659838,
        "scores": {
          "completeness": 0.0,
          "validity": 0.0,
          "speed": 0.9738248189463935,
          "memory": 0.0
        },
        "rank": 3
      }
    ],
    "recommendations": [
      "Recommended model: gemma_7b_it_4bit (highest composite score)",
      "gemma_7b_it_4bit excels at: speed",
      "gemma_7b_it_4bit needs improvement in: completeness, validity, memory",
      "Falcon3-7B-Base excels at: memory",
      "Falcon3-7B-Base needs improvement in: completeness, validity, speed",
      "Meta-Llama-3-8B-Instruct excels at: speed",
      "Meta-Llama-3-8B-Instruct needs improvement in: completeness, validity, memory",
      "Best quality/performance balance: Meta-Llama-3-8B-Instruct"
    ]
  },
  "dryrun_analysis": {
    "timestamp": "2025-06-20T20:32:11.915746",
    "summary": {
      "total_models": 3,
      "total_test_files": 6,
      "total_successful": 0,
      "total_failed": 6,
      "overall_success_rate": 0.0,
      "best_model": "Meta-Llama-3-8B-Instruct",
      "worst_model": "Meta-Llama-3-8B-Instruct"
    },
    "by_model": {
      "Meta-Llama-3-8B-Instruct": {
        "total_files": 2,
        "successful": 0,
        "failed": 2,
        "file_results": {
          "Basic_Auth_PASS_use_case.robot": {
            "file": "Basic_Auth_PASS_use_case.robot",
            "success": false,
            "errors": [
              "Suite 'Basic Auth PASS use case' contains no tests or tasks.",
              "Error in file '/home/kkhalttunen/yamk_thesis_enhanced/data/test_cases/Meta-Llama-3-8B-Instruct/Basic_Auth_PASS_use_case.robot' on line 17: Unrecognized section header '** UC-LOGIN-001: Basic Authentication'. Valid sections: 'Settings', 'Variables', 'Test Cases', 'Tasks', 'Keywords' and 'Comments'."
            ],
            "warnings": [],
            "output": "[ ERROR ] Error in file '/home/kkhalttunen/yamk_thesis_enhanced/data/test_cases/Meta-Llama-3-8B-Instruct/Basic_Auth_PASS_use_case.robot' on line 17: Unrecognized section header '** UC-LOGIN-001: Basic Authentication'. Valid sections: 'Settings', 'Variables', 'Test Cases', 'Tasks', 'Keywords' and 'Comments'.\n[ ERROR ] Suite 'Basic Auth PASS use case' contains no tests or tasks.\n\nTry --help for usage information.\n",
            "error_types": [
              "other",
              "other"
            ],
            "return_code": 252
          },
          "Basic_Auth_FAIL_use_case.robot": {
            "file": "Basic_Auth_FAIL_use_case.robot",
            "success": false,
            "errors": [
              "No keyword with name 'Note: You can run this test case using Robot Framework, and it should pass if the cancel button functionality is working correctly. If the test case fails, it indicates that there is an issue with the cancel button functionality. You can modify the test case as needed to better test the functionality.' found",
              "No keyword with name 'Click Button' found",
              "No keyword with name 'Keywords Used:' found",
              "No keyword with name 'https://the-internet.herokuapp.com/basic_auth' found",
              "No keyword with name 'Verify Page Contains' found",
              "No keyword with name 'chrome' found",
              "No keyword with name 'Wait Until Page Contains' found",
              "No keyword with name 'Maximize Browser Window' found"
            ],
            "warnings": [],
            "output": "==============================================================================\nBasic Auth FAIL use case :: Tests the cancel button functionality on the ba...\n==============================================================================\nTest Login Functionality :: Tests the cancel button functionality ... | FAIL |\nSetup failed:\nSeveral failures occurred:\n\n1) No keyword with name 'https://the-internet.herokuapp.com/basic_auth' found.\n\n2) No keyword with name 'chrome' found.\n\n3) No keyword with name 'Maximize Browser Window' found.\n\nAlso teardown failed:\nSeveral failures occurred:\n\n1) Keyword 'Close Browser' expected 0 arguments, got 1.\n\n2) No keyword with name 'Keywords Used:' found.\n\n3) No keyword with name 'Maximize Browser Window' found.\n\n4) No keyword with name 'Click Button' found. Did you try using keyword 'Browser.Click' and forgot to use enough whitespace between keyword and arguments?\n\n5) No keyword with name 'Wait Until Page Contains' found.\n\n6) No keyword with name 'Verify Page Contains' found.\n\n7) Keyword 'Close Browser' expected 0 arguments, got 1.\n\n8) No keyword with name 'Note: You can run this test case using Robot Framework, and it should pass if the cancel button functionality is working correctly. If the test case fails, it indicates that there is an issue with the cancel button functionality. You can modify the test case as needed to better test the functionality.' found.\n------------------------------------------------------------------------------\nBasic Auth FAIL use case :: Tests the cancel button functionality ... | FAIL |\n1 test, 0 passed, 1 failed\n==============================================================================\nOutput:  NONE\n",
            "error_types": [
              "missing_keyword",
              "missing_keyword",
              "missing_keyword",
              "missing_keyword",
              "missing_keyword",
              "missing_keyword",
              "missing_keyword",
              "missing_keyword"
            ],
            "return_code": 1
          }
        },
        "errors": [
          "Suite 'Basic Auth PASS use case' contains no tests or tasks.",
          "Error in file '/home/kkhalttunen/yamk_thesis_enhanced/data/test_cases/Meta-Llama-3-8B-Instruct/Basic_Auth_PASS_use_case.robot' on line 17: Unrecognized section header '** UC-LOGIN-001: Basic Authentication'. Valid sections: 'Settings', 'Variables', 'Test Cases', 'Tasks', 'Keywords' and 'Comments'.",
          "No keyword with name 'Note: You can run this test case using Robot Framework, and it should pass if the cancel button functionality is working correctly. If the test case fails, it indicates that there is an issue with the cancel button functionality. You can modify the test case as needed to better test the functionality.' found",
          "No keyword with name 'Click Button' found",
          "No keyword with name 'Keywords Used:' found",
          "No keyword with name 'https://the-internet.herokuapp.com/basic_auth' found",
          "No keyword with name 'Verify Page Contains' found",
          "No keyword with name 'chrome' found",
          "No keyword with name 'Wait Until Page Contains' found",
          "No keyword with name 'Maximize Browser Window' found"
        ],
        "warnings": [],
        "execution_time": 0.911583,
        "success_rate": 0.0
      },
      "Falcon3-7B-Base": {
        "total_files": 2,
        "successful": 0,
        "failed": 2,
        "file_results": {
          "Basic_Auth_PASS_use_case.robot": {
            "file": "Basic_Auth_PASS_use_case.robot",
            "success": false,
            "errors": [],
            "warnings": [],
            "output": "==============================================================================\nBasic Auth PASS use case :: Automated test for login functionality            \n==============================================================================\nTest Login Functionality :: Automated test for login functionality    | FAIL |\nTeardown failed:\nKeyword 'Close Browser' expected 0 arguments, got 1.\n------------------------------------------------------------------------------\nBasic Auth PASS use case :: Automated test for login functionality    | FAIL |\n1 test, 0 passed, 1 failed\n==============================================================================\nOutput:  NONE\n",
            "error_types": [],
            "return_code": 1
          },
          "Basic_Auth_FAIL_use_case.robot": {
            "file": "Basic_Auth_FAIL_use_case.robot",
            "success": false,
            "errors": [],
            "warnings": [],
            "output": "==============================================================================\nBasic Auth FAIL use case :: Automated test for login functionality            \n==============================================================================\nTest Login Functionality :: Automated test for login functionality    | FAIL |\nTeardown failed:\nKeyword 'Close Browser' expected 0 arguments, got 1.\n------------------------------------------------------------------------------\nBasic Auth FAIL use case :: Automated test for login functionality    | FAIL |\n1 test, 0 passed, 1 failed\n==============================================================================\nOutput:  NONE\n",
            "error_types": [],
            "return_code": 1
          }
        },
        "errors": [],
        "warnings": [],
        "execution_time": 1.14445,
        "success_rate": 0.0
      },
      "gemma_7b_it_4bit": {
        "total_files": 2,
        "successful": 0,
        "failed": 2,
        "file_results": {
          "Basic_Auth_PASS_use_case.robot": {
            "file": "Basic_Auth_PASS_use_case.robot",
            "success": false,
            "errors": [
              "Suite 'Basic Auth PASS use case' contains no tests or tasks.",
              "Error in file '/home/kkhalttunen/yamk_thesis_enhanced/data/test_cases/gemma_7b_it_4bit/Basic_Auth_PASS_use_case.robot' on line 17: Unrecognized section header '**'. Valid sections: 'Settings', 'Variables', 'Test Cases', 'Tasks', 'Keywords' and 'Comments'."
            ],
            "warnings": [],
            "output": "[ ERROR ] Error in file '/home/kkhalttunen/yamk_thesis_enhanced/data/test_cases/gemma_7b_it_4bit/Basic_Auth_PASS_use_case.robot' on line 17: Unrecognized section header '**'. Valid sections: 'Settings', 'Variables', 'Test Cases', 'Tasks', 'Keywords' and 'Comments'.\n[ ERROR ] Suite 'Basic Auth PASS use case' contains no tests or tasks.\n\nTry --help for usage information.\n",
            "error_types": [
              "other",
              "other"
            ],
            "return_code": 252
          },
          "Basic_Auth_FAIL_use_case.robot": {
            "file": "Basic_Auth_FAIL_use_case.robot",
            "success": false,
            "errors": [
              "No keyword with name 'Open the browser' found",
              "No keyword with name 'Navigate to the basic authentication page' found",
              "No keyword with name 'Expected Results:**' found",
              "No keyword with name 'The user is not logged in to the website.' found",
              "No keyword with name 'The user has seen the text \"Not authorized\" on the page.' found",
              "No keyword with name 'Close the browser' found"
            ],
            "warnings": [],
            "output": "==============================================================================\nBasic Auth FAIL use case :: ** This test case verifies that the user can ca...\n==============================================================================\nTest Login Functionality :: ** This test case verifies that the us... | FAIL |\nSetup failed:\nSeveral failures occurred:\n\n1) No keyword with name 'Open the browser' found. Did you mean:\n    Browser.Open Browser\n\n2) No keyword with name 'Navigate to the basic authentication page' found.\n\nAlso teardown failed:\nSeveral failures occurred:\n\n1) No keyword with name 'Close the browser' found. Did you mean:\n    Browser.Close Browser\n    Close Browser\n\n2) No keyword with name 'Expected Results:**' found.\n\n3) No keyword with name 'The user is not logged in to the website.' found.\n\n4) No keyword with name 'The user has seen the text \"Not authorized\" on the page.' found.\n------------------------------------------------------------------------------\nBasic Auth FAIL use case :: ** This test case verifies that the us... | FAIL |\n1 test, 0 passed, 1 failed\n==============================================================================\nOutput:  NONE\n",
            "error_types": [
              "missing_keyword",
              "missing_keyword",
              "missing_keyword",
              "missing_keyword",
              "missing_keyword",
              "missing_keyword"
            ],
            "return_code": 1
          }
        },
        "errors": [
          "Suite 'Basic Auth PASS use case' contains no tests or tasks.",
          "Error in file '/home/kkhalttunen/yamk_thesis_enhanced/data/test_cases/gemma_7b_it_4bit/Basic_Auth_PASS_use_case.robot' on line 17: Unrecognized section header '**'. Valid sections: 'Settings', 'Variables', 'Test Cases', 'Tasks', 'Keywords' and 'Comments'.",
          "No keyword with name 'Open the browser' found",
          "No keyword with name 'Navigate to the basic authentication page' found",
          "No keyword with name 'Expected Results:**' found",
          "No keyword with name 'The user is not logged in to the website.' found",
          "No keyword with name 'The user has seen the text \"Not authorized\" on the page.' found",
          "No keyword with name 'Close the browser' found"
        ],
        "warnings": [],
        "execution_time": 0.6554679999999999,
        "success_rate": 0.0
      }
    },
    "error_analysis": {
      "error_type_distribution": {
        "other": 4,
        "missing_keyword": 14
      },
      "common_errors": {
        "Suite 'Basic Auth PASS use case' contains no tests or tasks.": 2,
        "Error in file '/home/kkhalttunen/yamk_thesis_enhanced/data/test_cases/Meta-Llama-3-8B-Instruct/Basic_Auth_PASS_use_case.robot' on line 17: Unrecognized section header '** UC-LOGIN-001: Basic Authentication'. Valid sections: 'Settings', 'Variables', 'Test Cases', 'Tasks', 'Keywords' and 'Comments'.": 1,
        "No keyword with name 'Note: You can run this test case using Robot Framework, and it should pass if the cancel button functionality is working correctly. If the test case fails, it indicates that there is an issue with the cancel button functionality. You can modify the test case as needed to better test the functionality.' found": 1,
        "No keyword with name 'Click Button' found": 1,
        "No keyword with name 'Keywords Used:' found": 1,
        "No keyword with name 'https://the-internet.herokuapp.com/basic_auth' found": 1,
        "No keyword with name 'Verify Page Contains' found": 1,
        "No keyword with name 'chrome' found": 1,
        "No keyword with name 'Wait Until Page Contains' found": 1,
        "No keyword with name 'Maximize Browser Window' found": 1,
        "Error in file '/home/kkhalttunen/yamk_thesis_enhanced/data/test_cases/gemma_7b_it_4bit/Basic_Auth_PASS_use_case.robot' on line 17: Unrecognized section header '**'. Valid sections: 'Settings', 'Variables', 'Test Cases', 'Tasks', 'Keywords' and 'Comments'.": 1,
        "No keyword with name 'Open the browser' found": 1,
        "No keyword with name 'Navigate to the basic authentication page' found": 1,
        "No keyword with name 'Expected Results:**' found": 1,
        "No keyword with name 'The user is not logged in to the website.' found": 1,
        "No keyword with name 'The user has seen the text \"Not authorized\" on the page.' found": 1,
        "No keyword with name 'Close the browser' found": 1
      },
      "model_error_patterns": {
        "Meta-Llama-3-8B-Instruct": {
          "other": 2,
          "missing_keyword": 8
        },
        "Falcon3-7B-Base": {},
        "gemma_7b_it_4bit": {
          "other": 2,
          "missing_keyword": 6
        }
      },
      "top_errors": [
        [
          "Suite 'Basic Auth PASS use case' contains no tests or tasks.",
          2
        ],
        [
          "Error in file '/home/kkhalttunen/yamk_thesis_enhanced/data/test_cases/Meta-Llama-3-8B-Instruct/Basic_Auth_PASS_use_case.robot' on line 17: Unrecognized section header '** UC-LOGIN-001: Basic Authentication'. Valid sections: 'Settings', 'Variables', 'Test Cases', 'Tasks', 'Keywords' and 'Comments'.",
          1
        ],
        [
          "No keyword with name 'Note: You can run this test case using Robot Framework, and it should pass if the cancel button functionality is working correctly. If the test case fails, it indicates that there is an issue with the cancel button functionality. You can modify the test case as needed to better test the functionality.' found",
          1
        ],
        [
          "No keyword with name 'Click Button' found",
          1
        ],
        [
          "No keyword with name 'Keywords Used:' found",
          1
        ],
        [
          "No keyword with name 'https://the-internet.herokuapp.com/basic_auth' found",
          1
        ],
        [
          "No keyword with name 'Verify Page Contains' found",
          1
        ],
        [
          "No keyword with name 'chrome' found",
          1
        ],
        [
          "No keyword with name 'Wait Until Page Contains' found",
          1
        ],
        [
          "No keyword with name 'Maximize Browser Window' found",
          1
        ]
      ]
    },
    "comparative_analysis": {
      "success_rates": {
        "Meta-Llama-3-8B-Instruct": 0.0,
        "Falcon3-7B-Base": 0.0,
        "gemma_7b_it_4bit": 0.0
      },
      "error_prone_models": [
        "Meta-Llama-3-8B-Instruct"
      ],
      "most_stable_models": [
        "Falcon3-7B-Base",
        "gemma_7b_it_4bit"
      ],
      "execution_efficiency": {
        "Meta-Llama-3-8B-Instruct": {
          "avg_time_per_file": 0.4557915,
          "total_time": 0.911583
        },
        "Falcon3-7B-Base": {
          "avg_time_per_file": 0.572225,
          "total_time": 1.14445
        },
        "gemma_7b_it_4bit": {
          "avg_time_per_file": 0.32773399999999997,
          "total_time": 0.6554679999999999
        }
      }
    }
  }
}