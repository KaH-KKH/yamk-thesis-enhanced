
        <!DOCTYPE html>
        <html>
        <head>
            <title>LLM Evaluation Dashboard</title>
            <style>
                body { font-family: Arial, sans-serif; margin: 20px; }
                .header { background-color: #f0f0f0; padding: 20px; border-radius: 10px; }
                .info-box { background-color: #e8f4f8; padding: 15px; border-radius: 5px; margin: 10px 0; }
                .metric-card { 
                    display: inline-block; 
                    background-color: #fff; 
                    border: 1px solid #ddd; 
                    border-radius: 5px; 
                    padding: 15px; 
                    margin: 10px;
                    width: 200px;
                }
                .winner { background-color: #d4edda; }
                .section { margin-top: 30px; }
                table { border-collapse: collapse; width: 100%; }
                th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
                th { background-color: #f2f2f2; }
            </style>
        </head>
        <body>
            <div class="header">
                <h1>LLM Evaluation Dashboard</h1>
                <p>Generated: 2025-06-20 20:32:16</p>
                <p>Models evaluated: Meta-Llama-3-8B-Instruct, Falcon3-7B-Base, gemma_7b_it_4bit</p>
            </div>
            
            
                <div class="info-box">
                    <h3>LLM Evaluator Information</h3>
                    <p><strong>Model:</strong> mistral</p>
                    <p><strong>Selection reason:</strong> Selected as neutral evaluator (not in evaluated models: ['Meta-Llama-3-8B-Instruct', 'Falcon3-7B-Base', 'gemma_7b_it_4bit'])</p>
                </div>
            
            
            <div class="section">
                <h2>Summary</h2>
                <div class="metrics-container">
        
                    <div class="metric-card winner">
                        <h3>Quality Perplexity</h3>
                        <p><strong>Winner:</strong> Falcon3-7B-Base</p>
                        <p><strong>Score:</strong> 8.3566</p>
                    </div>
                
                </div>
            </div>
            
            <div class="section">
                <h2>Detailed Results</h2>
                <table>
                    <tr>
                        <th>Model</th>
                        <th>UC Success Rate</th>
                        <th>TC Success Rate</th>
                        <th>Total Time (s)</th>
                        <th>Memory (MB)</th>
                    </tr>
        
                    <tr>
                        <td>Meta-Llama-3-8B-Instruct</td>
                        <td>2/2 (100.0%)</td>
                        <td>3/3 (100.0%)</td>
                        <td>1454.73</td>
                        <td>1566.59</td>
                    </tr>
            
                    <tr>
                        <td>Falcon3-7B-Base</td>
                        <td>2/2 (100.0%)</td>
                        <td>3/3 (100.0%)</td>
                        <td>3262.04</td>
                        <td>11.39</td>
                    </tr>
            
                    <tr>
                        <td>gemma_7b_it_4bit</td>
                        <td>2/2 (100.0%)</td>
                        <td>3/3 (100.0%)</td>
                        <td>1433.39</td>
                        <td>136.02</td>
                    </tr>
            
                </table>
            </div>
            
            <div class="section">
                <h2>Recommendations</h2>
                <ul>
        <li>Overall recommendation: **Falcon3-7B-Base** (best in 1 metrics)</li><li>
**Extended Metrics Insights:**</li>
                </ul>
            </div>
            
            <div class="section">
                <h2>Visualizations</h2>
                <p>See generated PNG files in the results directory.</p>
            </div>
        </body>
        </html>
        