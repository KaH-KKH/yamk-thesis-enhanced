# Comprehensive LLM Evaluation Report
**Generated:** 2025-07-22T20:55:18.764112
**Models:** stablelm_3b

**LLM Evaluator:** mistral
**Evaluator Selection:** Selected as neutral evaluator (not in evaluated models: ['stablelm_3b'])

## Executive Summary

## Combined Evaluation Results

| Model | BLEU | ROUGE-L | BERTScore | METEOR | LLM Score | Overall |
|-------|------|---------|-----------|---------|-----------|---------|

## Robot Framework Dryrun Analysis

**Overall Success Rate:** 0.0%

| Model | Success Rate | Failed Tests | Most Common Error |
|-------|--------------|--------------|-------------------|
| stablelm_3b | 0.0% | 2/2 | missing_keyword |

No significant differences found between models.

### Key Findings


## Performance Analysis

| Model | Total Time (s) | Memory (MB) | Files/Second |
|-------|----------------|-------------|--------------|
| stablelm_3b | 274.13 | 2790.80 | 0.01 |

## Detailed Recommendations

- No significant differences found between models.

## Artifacts Generated

The following files have been generated:
- Individual model results (JSON)
- Comparison report (JSON)
- Metric comparison charts (PNG)
- Quality metrics heatmap (PNG)
- UX metrics radar chart (HTML)
- Comprehensive dashboard (HTML)
