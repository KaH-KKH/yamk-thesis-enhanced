# Comprehensive LLM Evaluation Report
**Generated:** 2025-07-23T11:26:56.379617
**Models:** tinyllama, phi2, pythia_1b, opt_1.3b, stablelm_3b

**LLM Evaluator:** mistral
**Evaluator Selection:** Selected as neutral evaluator (not in evaluated models: ['tinyllama', 'phi2', 'pythia_1b', 'opt_1.3b', 'stablelm_3b'])

## Executive Summary

## Combined Evaluation Results

| Model | BLEU | ROUGE-L | BERTScore | METEOR | LLM Score | Overall |
|-------|------|---------|-----------|---------|-----------|---------|

## Robot Framework Dryrun Analysis

**Overall Success Rate:** 0.0%

| Model | Success Rate | Failed Tests | Most Common Error |
|-------|--------------|--------------|-------------------|
| tinyllama | 0.0% | 2/2 | missing_keyword |
| phi2 | 0.0% | 2/2 | missing_keyword |
| pythia_1b | 0.0% | 2/2 | None |
| opt_1.3b | 0.0% | 2/2 | None |
| stablelm_3b | 0.0% | 2/2 | None |

Overall recommendation: **tinyllama** (best in 1 metrics)

### Key Findings

- **Quality Perplexity**: tinyllama (Score: 6.5122)

## Performance Analysis

| Model | Total Time (s) | Memory (MB) | Files/Second |
|-------|----------------|-------------|--------------|
| tinyllama | 88.35 | 1421.40 | 0.04 |
| phi2 | 426.53 | 9711.46 | 0.01 |
| pythia_1b | 73.52 | 23.32 | 0.06 |
| opt_1.3b | 65.12 | 71.10 | 0.05 |
| stablelm_3b | 82.68 | 47.38 | 0.07 |

## Extended Analysis

### Consistency Analysis

### Quality vs Performance Trade-offs

**tinyllama:**
- Quality Score: 0.00%
- Speed-Quality Ratio: 0.000
- Efficiency Score: 0.000

**phi2:**
- Quality Score: 0.00%
- Speed-Quality Ratio: 0.000
- Efficiency Score: 0.000

**pythia_1b:**
- Quality Score: 0.00%
- Speed-Quality Ratio: 0.000
- Efficiency Score: 0.000

**opt_1.3b:**
- Quality Score: 0.00%
- Speed-Quality Ratio: 0.000
- Efficiency Score: 0.000

**stablelm_3b:**
- Quality Score: 0.00%
- Speed-Quality Ratio: 0.000
- Efficiency Score: 0.000

### Model Rankings

1. **pythia_1b** (Score: 0.466)
2. **opt_1.3b** (Score: 0.332)
3. **stablelm_3b** (Score: 0.310)
4. **tinyllama** (Score: 0.176)
5. **phi2** (Score: 0.000)

## Detailed Recommendations

- Overall recommendation: **tinyllama** (best in 1 metrics)
- 
**Extended Metrics Insights:**

## Artifacts Generated

The following files have been generated:
- Individual model results (JSON)
- Comparison report (JSON)
- Metric comparison charts (PNG)
- Quality metrics heatmap (PNG)
- UX metrics radar chart (HTML)
- Comprehensive dashboard (HTML)
